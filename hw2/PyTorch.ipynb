{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "Follow the tutorial about how to utilize Google Colab but **don't install PyTorch** as mentioned in the blog post.\n",
    "\n",
    "Turkish:\n",
    "https://medium.com/deep-learning-turkiye/google-colab-ile-%C3%BCcretsiz-gpu-kullan%C4%B1m%C4%B1-30fdb7dd822e\n",
    "\n",
    "English:\n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part probably will be enough for utilizing Drive in Colab\n",
    "# but examine links above if you encounter with problems.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, you will work on Architectural Heritage Elements Dataset and classify these elements into 10 categories\n",
    "\n",
    "After having mounted the Jupyter Notebook to Google Drive, navigate the following address: https://drive.google.com/drive/folders/1PLXZYjGeaM1rekMKUTo8mlaaPeFOrBft?usp=sharing\n",
    "\n",
    "\n",
    "Add this folder entirely to your Google Drive. If you have done it correctly, then you should be able to see *data* folder in your drive.\n",
    "\n",
    "You can examine the dataset in the following address: https://old.datahub.io/dataset/architectural-heritage-elements-image-dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to choose the right runtime from the menu above. (GPU should be selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "# This command should return some information about the GPU status if the runtime is right. \n",
    "# In addition to that, if you encounter memory issues, you can diagnose your model by this command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are free to utilize Pytorch methods in this part of the homework. You will be using pretained models ResNet-50, DenseNet-121 and your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All libraries are already presented in Colab Servers, we don't need to install anything with pip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Models\n",
    "\n",
    "You can find tutorials on how to load those models at pytorch.org . Don't forget to use pretrained=True if you wish to do finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet-50 and DenseNet-121 model seperately here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Model\n",
    "\n",
    "Additionally, build your own model which is different from the other models, train on the Architectural Heritage Elements dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TO DO: Your neural network design\n",
    "        super(YourModel, self).__init__()\n",
    "        pass\n",
    "        self.seq = nn.Sequential(nn.Linear(10,10))\n",
    "    def forward(self, x):\n",
    "        # TO DO: Your neural network design\n",
    "        out = None\n",
    "        return out\n",
    "\n",
    "model = YourModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Here are some training parameters which you can tweak\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "regularization_rate = 0\n",
    "n_epochs = 10\n",
    "use_gpu = True\n",
    "test_every = 3\n",
    "###\n",
    "\n",
    "# You may want to tweak them too and you can use different parameter settings for different models. \n",
    "# These are just examples\n",
    "optimizer = optim.SGD(params=None, lr=learning_rate)\n",
    "criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "Here we provide you the codes for loading the train data, validation data and test data. Please ensure that you understood how PyTorch methods like ImageFolder, DataLoader and transformations work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "val_transforms = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "test_transforms = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "train_dataset = ImageFolder('drive/My Drive/data/train', train_transforms)\n",
    "val_dataset = ImageFolder('drive/My Drive/data/val', val_transforms)\n",
    "test_dataset = ImageFolder('drive/My Drive/data/test', test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "test_loader = DataLoader(dataset=val_dataset, batch_size=32, num_workers=4, shuffle=False)\n",
    "val_loader = DataLoader(dataset=test_dataset, batch_size=32, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own model\n",
    "\n",
    "Don't forget to include appropriate regularizations. Choose appropriate set of hyperparameters such as Learning Rate etc. You may insert new cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It modifies the behaviour of modules like BatchNorm and Dropout for training purposes\n",
    "# Use your own model\n",
    "model.train()\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    criteria.cuda()\n",
    "\n",
    "# Some example diagnostics.\n",
    "\n",
    "# Loss for every iteration\n",
    "losses_iter_train = []\n",
    "# Loss for epoch (averaging the iteration-wise loss)\n",
    "losses_epoch_train = []\n",
    "accuracy_iter_train = []\n",
    "accuracy_epoch_train = []\n",
    "\n",
    "losses_iter_val = []\n",
    "losses_epoch_val = []\n",
    "accuracy_iter_val = []\n",
    "accuracy_epoch_val = []\n",
    "\n",
    "# Write the training loop\n",
    "for epoch in range(n_epochs):\n",
    "    for ix, data in train_loader:\n",
    "        model.zero_grad()\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        pass\n",
    "    if epoch % 3 == 1:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "                # Measure the performance in validation set.\n",
    "            \n",
    "    model.train()\n",
    "    \n",
    "        # Fill the rest...\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model\n",
    "\n",
    "Measure the performance against test set. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It modifies the behaviour of modules like BatchNorm and Dropout for test purposes\n",
    "# Dropout no longer works when .eval() is called.\n",
    "# BatchNorm uses the learned parameters\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        # Fill the rest..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-50\n",
    "## Train ResNet-50\n",
    "\n",
    "Avoid overfitting and underfitting as much as possible. **Try to get highest validation and test accuracy (at least 65%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the same training mechanism above. Now, you will use ResNet-50 as your model        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the same testing mechanism above. Now, you will use the ResNet model you trained above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training and validation losses versus number of iterations or epochs for ResNet-50 on the same plot and obtain test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-121\n",
    "## Train DenseNet-121\n",
    "\n",
    "Avoid overfitting and underfitting as much as possible. **Try to get highest validation and test accuracy (at least 65%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the same training mechanism above. Now, you will use DenseNet-121 as your model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the same testing mechanism above. Now, you will use the DenseNet model you trained above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training and validation losses versus number of iterations or epochs for DenseNet-121 on the same plot and obtain test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNorm Comparison\n",
    "\n",
    "**Create two models one with batchnorm layers and one without batchnorm layers. Train them. If your YourModel() satisfies any of these conditions, you can use it for comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model with BatchNorm and train it. Skip this if you use YourModel() for this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model without BatchNorm and train it. Skip this if you use YourModel() for this condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each, plot the training and validation losses versus number of iterations or epochs and compare test accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Comparison\n",
    "\n",
    "**Create two models one with dropout layers and one without dropout layers. Train them. If your YourModel() satisfies any of these conditions, you can use it for comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model with Dropout and train it. Skip this if you use YourModel() for this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model without Dropout and train it. Skip this if you use YourModel() for this condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each, plot the training and validation losses versus number of iterations or epochs and compare test accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Comparison\n",
    "\n",
    "**Optimize two identical models one with SGD+Momentum and one with Adam. If your training for YourModel() satisfies any of these conditions, you can use it for comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model with SGD+Momentum. Skip this if you use YourModel() for this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model with Adam. Skip this if you use YourModel() for this condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each, plot the training and validation losses versus number of iterations or epochs and compare test accuracies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After you have completed the training, save your best model using the following command\n",
    "#### Upload your best model to Google Drive and copy your link here: *link*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 111\n",
    "torch.save(model.state_dict(), 'drive/blg561/{}.pth'.format(student_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
