{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modelling Task (45 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to implement the dataset object and and create dataloaders from it. Then you need to implement network models, training loops and evaluation and generation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in required parts of code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3992,
     "status": "ok",
     "timestamp": 1609426366377,
     "user": {
      "displayName": "Fırat Öncel",
      "photoUrl": "",
      "userId": "09411010771070540721"
     },
     "user_tz": -180
    },
    "id": "xk97LrSrjOOO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CE3SB2yTkUPs"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixcE5OBNjOOR"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_length,\n",
    "        path,\n",
    "        train=True,\n",
    "        train_split=0.8,\n",
    "        device='cuda'\n",
    "    ):\n",
    "    \"\"\" Dataset constructor\n",
    "    Args:\n",
    "        seq_length: sequence length (window size)\n",
    "        path: path of the data file\n",
    "        train: train vs validation option\n",
    "        train_split: ratio of the training data\n",
    "        device: cpu or cuda\n",
    "    \"\"\"\n",
    "        self.seq_length = seq_length\n",
    "        self.mode = mode\n",
    "        self.train_split = train_split\n",
    "        self.path = train_path\n",
    "        self.all_data, self.train_data, self.eval_data = self._read_data()\n",
    "        \n",
    "        self.unique_data = self._find_unique()\n",
    "\n",
    "        self.idx_data = {idx: data for idx, data in enumerate(self.unique_data)}\n",
    "        self.data_idx = {data: idx for idx, data in enumerate(self.unique_data)}\n",
    "        \n",
    "        self.data = self.train_data if train else self.eval_data\n",
    "\n",
    "        self.indexed_data = np.array([self.data_idx[i] for i in self.data])\n",
    "        \n",
    "        self.indexed_data = torch.from_numpy(self.indexed_data).to(device)\n",
    "\n",
    "    def _read_data(self):\n",
    "        \"\"\" Reads data word by word and splits data into training and validation\n",
    "            Fill in parts with None \n",
    "        \"\"\"\n",
    "        text = open(self.path, 'rb').read().decode(encoding='utf-8')\n",
    "        data = None\n",
    "        train_data = None\n",
    "        eval_data = None\n",
    "        return data, train_data, eval_data\n",
    "\n",
    "    def _find_unique(self):\n",
    "        \"\"\" Finds unique words and sorts them according to their frequency - most frequent first\n",
    "        \"\"\"\n",
    "        data_count = Counter(self.all_data)\n",
    "        return sorted(data_count, key=data_count.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Size of dataset\n",
    "            Fill in parts with None \n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Get sample with index idx, should return data and target\n",
    "            Uses sliding window\n",
    "            Fill in parts with None \n",
    "        \"\"\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oB7W7czijOOS"
   },
   "outputs": [],
   "source": [
    "\"\"\" Get dataset and dataloader for train and validation\n",
    "    Using only 1 book from the data is sufficient\n",
    "\"\"\"\n",
    "train_dataset = None\n",
    "trainloader = None\n",
    "eval_dataset = None\n",
    "evalloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d6cWdiMjOOT"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, embed_size=64, hidden_size=64,\n",
    "                 hidden_layers=2, seq_length=20, dropout=0.1, device='cuda'):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \"\"\" RNNModel constructor\n",
    "        Args:\n",
    "            ntoken: token size\n",
    "            embed_size: embedding dimension size\n",
    "            hidden_size: hidden layer dimension size\n",
    "            hidden_layers: number of hidden layers\n",
    "            seq_length: length of sequence\n",
    "            dropout: dropout\n",
    "            device: cpu or cuda\n",
    "        \"\"\"\n",
    "        \"\"\"Fill in parts with None\"\"\"\n",
    "        \n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.ntoken = ntoken\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        self.embed = None\n",
    "        self.rnn = None\n",
    "        self.linear = None\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        \"\"\"Forward pass for RNNModel\"\"\"\n",
    "        raise NotImplementedError\n",
    "        return logits, state\n",
    "    \n",
    "    def initialize(self, seq_length=None):\n",
    "        \"\"\" Initialize hidden states \"\"\"\n",
    "        raise NotImplementedError\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fakOEOAsjOOT"
   },
   "outputs": [],
   "source": [
    "class GatedModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, embed_size=64, hidden_size=64,\n",
    "                 hidden_layers=2, seq_length=20, dropout=0.1, device='cuda'):\n",
    "        super(GatedModel, self).__init__()\n",
    "        \"\"\" GatedModel constructor\n",
    "        Args:\n",
    "            ntoken: token size\n",
    "            embed_size: embedding dimension size\n",
    "            hidden_size: hidden layer dimension size\n",
    "            hidden_layers: number of hidden layers\n",
    "            seq_length: length of sequence\n",
    "            dropout: dropout\n",
    "            device: cpu or cuda\n",
    "        \"\"\"\n",
    "        \"\"\"Fill in parts with None\"\"\"\n",
    "        \n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.ntoken = ntoken\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        \n",
    "        self.embed = None\n",
    "        self.lstm = None\n",
    "        self.linear = None\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        \"\"\"Forward pass for LSTMModel\"\"\"\n",
    "        raise NotImplementedError\n",
    "        return logits, state\n",
    "    \n",
    "    def initialize(self, seq_length=None):\n",
    "        \"\"\" Initialize hidden states \"\"\"\n",
    "        raise NotImplementedError\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMnsEe4ojOOT"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, dataloader,\n",
    "                    log=True, log_interval=200, grad_clip=False, clip_val=0.5):\n",
    "    \"\"\" Single epoch training function\n",
    "    Args:\n",
    "        model: network model\n",
    "        criterion: loss function\n",
    "        optimizer: optimizer\n",
    "        dataloader: dataloader\n",
    "        log: print loss and perplexity? (boolean)\n",
    "        log_interval: interval to log\n",
    "        grad_clip: perform gradient clipping? (boolean)\n",
    "        clip_val: value for gradient clipping\n",
    "    \"\"\"\n",
    "    \"\"\"Fill in parts with None\"\"\"\n",
    "    model.train()\n",
    "    state = model.initialize()\n",
    "    total_loss = 0\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        None\n",
    "\n",
    "        if grad_clip:\n",
    "            None\n",
    "\n",
    "        None\n",
    "        \n",
    "        if batch % log_interval == 0 and log:\n",
    "            None\n",
    "    return total_loss / (len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8axxPdGfjOOU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dataloader, log=True):\n",
    "    \"\"\" Evaluation function\n",
    "    Args:\n",
    "        model: network model\n",
    "        criterion: loss function\n",
    "        dataloader: dataloader\n",
    "        log: print loss and perplexity? (boolean)\n",
    "    \"\"\"\n",
    "    \"\"\"Fill in parts with None\"\"\"\n",
    "    model.eval()\n",
    "    state = model.initialize()\n",
    "    total_loss = 0\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        None\n",
    "    if log:\n",
    "        None\n",
    "    return total_loss / (len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuasM3w6jOOU"
   },
   "outputs": [],
   "source": [
    "def train(trainloader, evalloader, model, optimizer, criterion,\n",
    "          nepoch, grad_clip=False, clip_val=0.9 , log_interval=1,\n",
    "          scheduler=None, eval_during_train=True, eval_interval=1, \n",
    "          save_interval=1, model_name='model'):\n",
    "    \"\"\" Training function\n",
    "    Args:\n",
    "        trainloader: dataloader for training dataset\n",
    "        evalloader: dataloader for evaluation dataset\n",
    "        model: network model\n",
    "        optimizer: optimizer\n",
    "        criterion: loss function\n",
    "        nepoch: number of epochs\n",
    "        grad_clip: perform gradient clipping? (boolean)\n",
    "        clip_val: value for gradient clipping\n",
    "        log_interval: interval to log\n",
    "        optimizer: learning rate scheduler\n",
    "        eval_during_train: perform evaluation during training? (boolean)\n",
    "        eval_interval: interval to evaluate\n",
    "        save_interval: interval to save\n",
    "        model_name: model name to save\n",
    "    \"\"\"\n",
    "    \"\"\"Fill in parts with None\"\"\"\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    for ep in range(nepoch):\n",
    "        if scheduler:\n",
    "            None\n",
    "        train_loss = None\n",
    "        train_losses = None\n",
    "        if ep % log_interval == 0:\n",
    "            print({'Epoch': ep, 'loss': train_loss})\n",
    "        if eval_during_train and ep % eval_interval == 0:\n",
    "            eval_loss = None\n",
    "            validation_losses = None\n",
    "        if ep % save_interval == 0:\n",
    "            torch.save(model, './models/'\n",
    "                       + model_name + '.p')\n",
    "    return train_losses, validation_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ye2n8de4jOOU"
   },
   "outputs": [],
   "source": [
    "def generate(model, data, data_idx_dict, idx_data_dict, \n",
    "             len_hist=50, len_gen=50, device='cuda'):\n",
    "    \"\"\" Generate text function\n",
    "        To get the predictions of the model, sample from the output distribution\n",
    "        instead of taking the argmax\n",
    "    Args:\n",
    "        model: network model\n",
    "        data: data\n",
    "        data_idx_dict: data to index dictionary\n",
    "        idx_data_dict: index to data dictionary\n",
    "        len_hist: length of history\n",
    "        len_gen: length to generate\n",
    "        device: cpu or cuda\n",
    "    \"\"\"\n",
    "    \"\"\"Fill in parts with None\"\"\"\n",
    "    model.eval()\n",
    "    state = model.initialize(len_hist)\n",
    "    for i in range(len_gen):\n",
    "        x = None\n",
    "        with torch.no_grad():\n",
    "            y_pred, state = None\n",
    "        last_logits = None\n",
    "        \"\"\"idx: sampled indices from the output distribution\"\"\"\n",
    "        idx = None \n",
    "        data.append(idx_data_dict[idx])\n",
    "    return ' '.join(data[-(len_hist+len_gen):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9i3QwJtjOOW"
   },
   "source": [
    "## Training and Experimentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and tune 3 networks as follows: Network with RNNModel without gradient clipping, network with RNNModel with gradient clipping, and network with GatedModel (LSTM or GRU according to your choice) without gradient clipping.  You should get a maximum validation perplexity of 120 for Pride and Prejudice and 125 for the other books. You should save your final models and provide them in the submission. You should plot the loss curves and perplexity curves for all 3 models in 2 figures (one for loss and one for perplexity). These plots should ve saved as a seperate image file and provided in submission for safety. Finally you should evaluate the final models and generate sample texts from each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence length should be at least 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch = 50\n",
    "lr = 0.1\n",
    "\n",
    "ntoken = len(train_dataset.unique_data)\n",
    "\n",
    "model = RNNModel(ntoken)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 50)\n",
    "train(trainloader, evalloader, model, optimizer, criterion, nepoch, grad_clip=False, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, criterion, evalloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model, list(eval_dataset.data.values[300:500]), train_dataset.data_idx, train_dataset.idx_data, len_hist=100, len_gen=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) Explain teacher forcing and give its advantages and disadvantages. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) Explain encoder-decoder sequence-to-sequence architectures. Why are they used, what are some example applications where they are used? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3) Why is attention used in encoder-decoder sequence-to-sequence architectures? (5 points)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Untitled.ipynb",
   "provenance": [
    {
     "file_id": "16kLX8XrOX8O8_ODtpf0T8y4QHRsLQFYT",
     "timestamp": 1609426256501
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
