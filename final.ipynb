{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lfd-hw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTqVo_nzFkoP"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.preprocessing import Imputer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression, mutual_info_regression, RFE\n",
        "import sklearn\n",
        "# import tflearn\n",
        "import tensorflow as tf\n",
        "import seaborn\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# faati test mest\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "# do not delete\n",
        "import random\n",
        "\n",
        "from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huyj0wMkNKyW"
      },
      "source": [
        "def make_submission(prediction, filename):\n",
        "    assert type(prediction) == np.ndarray, \"Pass a numpy.ndarray\"\n",
        "    assert prediction.shape[0] == 80, f\"Missing data points Expected 80 Got {prediction.shape[0]}\"\n",
        "    assert prediction.shape[1] == 595, f\"Number of features predicted is not correct Excpected 595 Got {prediction.shape[1]}\"\n",
        "    assert type(filename) == str, \"Filename must be a string\"\n",
        "    assert '.csv' in filename, \"Add extension '.csv'\"\n",
        "    \n",
        "    df = pd.DataFrame(prediction.flatten())\n",
        "    df.index.name = \"ID\"\n",
        "    df = df.rename(columns={0:\"predicted\"})\n",
        "    df.to_csv(filename)\n",
        "    print(f\"{filename} saved at {os.getcwd()}\")\n",
        "    return df"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEYThS7jNpDk"
      },
      "source": [
        "def remove_id_column(dataframe):\n",
        "    assert type(dataframe) == pd.core.frame.DataFrame, f\"{type(dataframe)} != pd.core.frame.DataFrame\"\n",
        "    return dataframe.drop(\"ID\", 1)\n"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huZlRLXSKbcC"
      },
      "source": [
        "def try_models(train,train_labels,test,test_labels, results):\n",
        "\n",
        "    def test_model(clf):\n",
        "\n",
        "        clf.fit(train, train_labels)\n",
        "        test_predict = clf.predict(test)\n",
        "        actual = test_labels.flatten()\n",
        "        predicted = test_predict.flatten()\n",
        "        scores = mean_squared_error(predicted, actual)\n",
        "\n",
        "        return scores\n",
        "\n",
        "    clf = linear_model.LinearRegression()\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'LinearRegression'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "    \n",
        "    clf = linear_model.Ridge()\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'Ridge'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "\n",
        "    clf = MultiOutputRegressor(SGDRegressor())\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'SGDRegressor'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "\n",
        "    clf = MultiOutputRegressor(linear_model.BayesianRidge())\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'BayesianRidge'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "    \n",
        "    clf = MultiOutputRegressor(linear_model.HuberRegressor())\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'HuberRegressor'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "    \n",
        "    clf = linear_model.Lasso(alpha=1e-4)\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'Lasso'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "        \n",
        "    clf = BaggingRegressor()\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'BaggingRegressor'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "\n",
        "    clf = ElasticNet()\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'ElasticNet'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "    \n",
        "    clf = RandomForestRegressor()\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'RandomForestRegressor'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "\n",
        "    clf = MultiOutputRegressor(AdaBoostRegressor())\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'AdaBoostRegressor'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "    \n",
        "    clf = MultiOutputRegressor(svm.SVR(kernel=\"linear\"))\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'SVR(kernel=\"linear\")'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "       \n",
        "    clf = MultiOutputRegressor(svm.SVR(kernel=\"rbf\"))\n",
        "    test_result = test_model(clf)\n",
        "    model_name = 'SVR(kernel=\"rbf\")'\n",
        "    if model_name in results.keys():\n",
        "        results[model_name].append(test_result)\n",
        "    else:\n",
        "        results.update({model_name:[test_result]})\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzZwCH7FuZH2"
      },
      "source": [
        "random.seed(1)\n",
        "def cv(data, labels, n_fold, model=None, shuffle=False):\n",
        "    kf = KFold(n_splits=n_fold, shuffle=shuffle)\n",
        "    results = {}\n",
        "    if model is not None:\n",
        "        results['YourModel'] = []\n",
        "    for train_index, test_index in kf.split(data):\n",
        "        train = data[train_index, :]\n",
        "        train_labels = labels[train_index, :]\n",
        "        test = data[test_index, :]\n",
        "        test_labels = labels[test_index, :]\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        # Fit on training set only.\n",
        "        scaler.fit(train)\n",
        "        # Apply transform to both the training set and the test set.\n",
        "        train = scaler.transform(train)\n",
        "        test = scaler.transform(test)\n",
        "\n",
        "        pca = PCA(0.70)\n",
        "        pca.fit(train)\n",
        "        train = pca.transform(train)\n",
        "        test = pca.transform(test)\n",
        "\n",
        "        if model == None:\n",
        "            results = try_models(train,train_labels,test,test_labels, results)\n",
        "        else:\n",
        "            model.fit(train, train_labels)\n",
        "            test_predict = model.predict(test)\n",
        "            actual = test_labels.flatten()\n",
        "            predicted = test_predict.flatten()\n",
        "            scores = mean_squared_error(predicted, actual)\n",
        "            results['YourModel'].append(scores)\n",
        "\n",
        "    # Add Variance and Mean Values as columns  \n",
        "    # to the results dataframe\n",
        "    results_df = pd.DataFrame(results).T\n",
        "    variance = results_df.var(axis=1)\n",
        "    mean = results_df.mean(axis=1)\n",
        "    results_df.insert(5, \"Var\", variance)\n",
        "    results_df.insert(6, \"Mean\", mean)  \n",
        "\n",
        "    return results_df"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL0eGe4ryIpA"
      },
      "source": [
        "def train_model(model, data, labels):\n",
        "    scaler = MinMaxScaler()\n",
        "    # Fit on training set only.\n",
        "    scaler.fit(data)\n",
        "    # Apply transform to both the training set and the test set.\n",
        "    data = scaler.transform(data)\n",
        "\n",
        "    pca = PCA(0.70)\n",
        "    pca.fit(data)\n",
        "    train = pca.transform(data)\n",
        "    print(train.shape)\n",
        "    model.fit(data, labels)\n",
        "    return model"
      ],
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voUMX5m_OwC8"
      },
      "source": [
        "X = pd.read_csv('train_t0.csv')\n",
        "Y = pd.read_csv('train_t1.csv')\n",
        "test = pd.read_csv('test_t0.csv')\n",
        "X = remove_id_column(X)\n",
        "Y = remove_id_column(Y)\n",
        "test = remove_id_column(test)"
      ],
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkkE3pB1wOrr"
      },
      "source": [
        "$t_0$ and $t_1$ might not be same for all samples thus searching outlier over features is quite meaningless. Lets check their differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpdzTj7twH0n"
      },
      "source": [
        "data = X.to_numpy()\n",
        "labels = Y.to_numpy()\n",
        "\n",
        "diff = labels - data\n",
        "diff_norm = sklearn.preprocessing.normalize(diff, axis=0)"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXroHHW81uo7"
      },
      "source": [
        "z = np.abs(stats.zscore(diff, 1))\n",
        "thresh = 4\n",
        "data_clean = data[(z<thresh).all(axis=1)]\n",
        "data_clean.shape\n",
        "labels_clean = data[(z<thresh).all(axis=1)]\n",
        "labels_clean.shape\n",
        "\n",
        "clf = linear_model.Ridge()\n",
        "clf.fit(data_clean, labels_clean)\n",
        "# clf = train_model(clf, data_clean, labels_clean)\n",
        "test = pd.read_csv('test_t0.csv')\n",
        "test = remove_id_column(test)\n",
        "predict = clf.predict(test)"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qA9vze1uo_",
        "outputId": "4730513b-ec07-43cb-dab5-d1eb0ffe2322"
      },
      "source": [
        "test_gonderdigim = pd.read_csv('batuyu_yok_ediyorum.csv')\n",
        "predict = make_submission(predict, 'batuyu_yok_eden_bu_muydu.csv')"
      ],
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batuyu_yok_eden_bu_muydu.csv saved at /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lQH2CZO1uo_",
        "outputId": "72b328f3-f4e9-413b-d400-4d98e651495a"
      },
      "source": [
        "print(predict.head())\n",
        "print(test_gonderdigim.head())\n",
        "print(predict.tail())\n",
        "print(test_gonderdigim.tail())"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    predicted\n",
            "ID           \n",
            "0    0.048603\n",
            "1    0.098349\n",
            "2    0.181086\n",
            "3    0.000000\n",
            "4    0.048603\n",
            "   ID  predicted\n",
            "0   0   0.048603\n",
            "1   1   0.098349\n",
            "2   2   0.181086\n",
            "3   3   0.000000\n",
            "4   4   0.048603\n",
            "       predicted\n",
            "ID              \n",
            "47595   0.129815\n",
            "47596   0.134323\n",
            "47597   0.036656\n",
            "47598   0.036656\n",
            "47599   0.310462\n",
            "          ID  predicted\n",
            "47595  47595   0.129815\n",
            "47596  47596   0.134323\n",
            "47597  47597   0.036656\n",
            "47598  47598   0.036656\n",
            "47599  47599   0.310462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQKAWRZcxVDM"
      },
      "source": [
        "for i in range(10):\n",
        "    plt.hist(diff[:, i], 200)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZpzpRb0ADe"
      },
      "source": [
        "for i in range(10):\n",
        "    plt.scatter(np.arange(len(diff[:,i])),diff[:, i])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2iDKtp-Fgs3",
        "outputId": "5c873e82-54bd-46d8-d6dd-6b805f32ea9f"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "clf = IsolationForest(random_state=0).fit(diff)\n",
        "k = clf.predict(diff)\n",
        "print(k.shape)\n",
        "print(np.sum(k==-1))\n",
        "data_clean = data[np.where(k==1)]\n",
        "clf2 = IsolationForest(random_state=0).fit(data)\n",
        "k2 = clf2.predict(data)\n",
        "print(np.sum(k2==-1))\n",
        "clf3 = IsolationForest(random_state=0).fit(labels)\n",
        "k3 = clf3.predict(labels)\n",
        "print(np.sum(k3==-1))\n",
        "anomalies = np.logical_and(k3==1, np.logical_and(k2==1, k==1))\n",
        "print(anomalies.shape)\n",
        "locations = np.where(anomalies)\n",
        "print(len(locations[0]))"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150,)\n",
            "9\n",
            "6\n",
            "6\n",
            "(150,)\n",
            "139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snnQgcNrGMR0",
        "outputId": "190c813e-89ce-4532-cd64-37e2b8812076"
      },
      "source": [
        "data_clean = data[locations]\n",
        "labels_clean = labels[locations]\n",
        "print(data_clean.shape)\n",
        "print(labels_clean.shape)"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(139, 595)\n",
            "(139, 595)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJvxnFb0UOKj"
      },
      "source": [
        "results = cv(data_clean, labels_clean, 5, shuffle=True)"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "2uL4j7ahWl0F",
        "outputId": "73be0935-cd4f-4d04-e84f-782acc644edf"
      },
      "source": [
        "results.head(20)"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>Var</th>\n",
              "      <th>Mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.003022</td>\n",
              "      <td>0.003014</td>\n",
              "      <td>0.002834</td>\n",
              "      <td>0.002689</td>\n",
              "      <td>0.002603</td>\n",
              "      <td>3.557636e-08</td>\n",
              "      <td>0.002833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.002896</td>\n",
              "      <td>0.002729</td>\n",
              "      <td>0.002592</td>\n",
              "      <td>0.002525</td>\n",
              "      <td>3.116417e-08</td>\n",
              "      <td>0.002732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDRegressor</th>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.002293</td>\n",
              "      <td>0.002229</td>\n",
              "      <td>0.002095</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>2.746103e-08</td>\n",
              "      <td>0.002302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BayesianRidge</th>\n",
              "      <td>0.002327</td>\n",
              "      <td>0.002159</td>\n",
              "      <td>0.002147</td>\n",
              "      <td>0.001993</td>\n",
              "      <td>0.002125</td>\n",
              "      <td>1.417797e-08</td>\n",
              "      <td>0.002150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HuberRegressor</th>\n",
              "      <td>0.003134</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.002898</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>2.986998e-08</td>\n",
              "      <td>0.002963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>0.002946</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.002760</td>\n",
              "      <td>0.002615</td>\n",
              "      <td>0.002552</td>\n",
              "      <td>3.202109e-08</td>\n",
              "      <td>0.002761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingRegressor</th>\n",
              "      <td>0.002642</td>\n",
              "      <td>0.002352</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.002408</td>\n",
              "      <td>0.002491</td>\n",
              "      <td>1.299822e-08</td>\n",
              "      <td>0.002488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>0.002750</td>\n",
              "      <td>0.002499</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.002311</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>2.908367e-08</td>\n",
              "      <td>0.002571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor</th>\n",
              "      <td>0.002458</td>\n",
              "      <td>0.002237</td>\n",
              "      <td>0.002237</td>\n",
              "      <td>0.002214</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>9.885953e-09</td>\n",
              "      <td>0.002288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostRegressor</th>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.002324</td>\n",
              "      <td>0.002298</td>\n",
              "      <td>0.002194</td>\n",
              "      <td>0.002394</td>\n",
              "      <td>1.699822e-08</td>\n",
              "      <td>0.002351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>0.003358</td>\n",
              "      <td>0.003384</td>\n",
              "      <td>0.003326</td>\n",
              "      <td>0.003326</td>\n",
              "      <td>0.003468</td>\n",
              "      <td>3.448985e-09</td>\n",
              "      <td>0.003373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR(kernel=\"linear\")</th>\n",
              "      <td>0.003422</td>\n",
              "      <td>0.003644</td>\n",
              "      <td>0.003415</td>\n",
              "      <td>0.003408</td>\n",
              "      <td>0.003309</td>\n",
              "      <td>1.517256e-08</td>\n",
              "      <td>0.003440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR(kernel=\"rbf\")</th>\n",
              "      <td>0.003358</td>\n",
              "      <td>0.003384</td>\n",
              "      <td>0.003326</td>\n",
              "      <td>0.003326</td>\n",
              "      <td>0.003468</td>\n",
              "      <td>3.448985e-09</td>\n",
              "      <td>0.003373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              0         1  ...           Var      Mean\n",
              "LinearRegression       0.003022  0.003014  ...  3.557636e-08  0.002833\n",
              "Ridge                  0.002920  0.002896  ...  3.116417e-08  0.002732\n",
              "SGDRegressor           0.002545  0.002293  ...  2.746103e-08  0.002302\n",
              "BayesianRidge          0.002327  0.002159  ...  1.417797e-08  0.002150\n",
              "HuberRegressor         0.003134  0.003130  ...  2.986998e-08  0.002963\n",
              "Lasso                  0.002946  0.002930  ...  3.202109e-08  0.002761\n",
              "BaggingRegressor       0.002642  0.002352  ...  1.299822e-08  0.002488\n",
              "ElasticNet             0.002750  0.002499  ...  2.908367e-08  0.002571\n",
              "RandomForestRegressor  0.002458  0.002237  ...  9.885953e-09  0.002288\n",
              "AdaBoostRegressor      0.002545  0.002324  ...  1.699822e-08  0.002351\n",
              "SVR                    0.003358  0.003384  ...  3.448985e-09  0.003373\n",
              "SVR(kernel=\"linear\")   0.003422  0.003644  ...  1.517256e-08  0.003440\n",
              "SVR(kernel=\"rbf\")      0.003358  0.003384  ...  3.448985e-09  0.003373\n",
              "\n",
              "[13 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHiemyV1ZswF",
        "outputId": "fedd886c-1cfb-4054-b39c-ca3dc017e352"
      },
      "source": [
        "results2 = results.drop(\"Mean\",1 )\n",
        "results2 = results2.drop(\"Var\", 1)\n",
        "results2.head(20)\n"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression         0.002243\n",
              "Ridge                    0.002238\n",
              "SGDRegressor             0.002305\n",
              "BayesianRidge            0.002154\n",
              "HuberRegressor           0.002255\n",
              "Lasso                    0.002236\n",
              "BaggingRegressor         0.002453\n",
              "ElasticNet               0.002569\n",
              "RandomForestRegressor    0.002247\n",
              "AdaBoostRegressor        0.002334\n",
              "SVR                      0.003351\n",
              "SVR(kernel=\"linear\")     0.003291\n",
              "SVR(kernel=\"rbf\")        0.003351\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VYbT2o70ioR",
        "outputId": "719ccb79-5591-47fa-ca74-b28ccd1f9ee0"
      },
      "source": [
        "from scipy import stats\n",
        "z = np.abs(stats.zscore(diff, 1))\n",
        "print(z)\n",
        "print(np.sum(z>4, axis=1))"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.27550312 0.42684763 0.05926019 ... 0.97315076 0.97315076 1.65221842]\n",
            " [0.04977388 0.11642169 0.10556146 ... 0.19023382 0.19023382 0.60581282]\n",
            " [0.33303279 0.26241309 0.69007624 ... 0.13325332 0.13325332 0.79129724]\n",
            " ...\n",
            " [0.85393891 0.60745419 1.48217688 ... 0.27721018 0.27721018 1.10369588]\n",
            " [0.21128766 0.10509232 0.27422087 ... 0.88766977 0.88766977 1.70621432]\n",
            " [0.45676521 0.05742982 0.24308232 ... 0.3140789  0.3140789  0.19442973]]\n",
            "[2 0 2 3 0 2 0 0 0 1 0 0 0 0 2 0 0 0 1 0 0 0 0 2 0 1 0 1 0 0 1 3 0 3 0 0 2\n",
            " 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 4 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 2 1 0 1 0 0 1 0 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 0 2 0 0 1 1 0 2 0 0 3 0 1 0 6 0 1 0 0 1 0 0 2 1 0 2 1 1 0\n",
            " 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkhuuCmM0t6b",
        "outputId": "4e65d878-4cf3-464d-9899-3f2cc7294106"
      },
      "source": [
        "z = np.abs(stats.zscore(diff, 1))\n",
        "thresh = 4\n",
        "data_clean = data[(z<thresh).all(axis=1)]\n",
        "data_clean.shape\n",
        "labels_clean = data[(z<thresh).all(axis=1)]\n",
        "labels_clean.shape"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91, 595)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyVuUQHmgBT6"
      },
      "source": [
        "z_results = cv(data_clean, labels_clean, 5, shuffle=True)"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "jMMC9YedgJi6",
        "outputId": "bc44875f-529e-4db1-a70f-34f96db3bc82"
      },
      "source": [
        "z_results.head(20)"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>Var</th>\n",
              "      <th>Mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.000509</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.001472</td>\n",
              "      <td>0.000527</td>\n",
              "      <td>1.855842e-07</td>\n",
              "      <td>0.000707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.000513</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>0.000530</td>\n",
              "      <td>1.848617e-07</td>\n",
              "      <td>0.000709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDRegressor</th>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.001136</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.001186</td>\n",
              "      <td>2.280844e-07</td>\n",
              "      <td>0.001446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BayesianRidge</th>\n",
              "      <td>0.000514</td>\n",
              "      <td>0.000451</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>1.858500e-07</td>\n",
              "      <td>0.000708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HuberRegressor</th>\n",
              "      <td>0.000533</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>1.988437e-07</td>\n",
              "      <td>0.000738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.000530</td>\n",
              "      <td>1.860553e-07</td>\n",
              "      <td>0.000709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingRegressor</th>\n",
              "      <td>0.002236</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>0.003856</td>\n",
              "      <td>0.001931</td>\n",
              "      <td>8.098340e-07</td>\n",
              "      <td>0.002313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>0.002531</td>\n",
              "      <td>0.001983</td>\n",
              "      <td>0.002398</td>\n",
              "      <td>0.004356</td>\n",
              "      <td>0.002504</td>\n",
              "      <td>8.498229e-07</td>\n",
              "      <td>0.002754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor</th>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.001432</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>0.003715</td>\n",
              "      <td>0.001780</td>\n",
              "      <td>8.196422e-07</td>\n",
              "      <td>0.002126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostRegressor</th>\n",
              "      <td>0.001628</td>\n",
              "      <td>0.001251</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.001487</td>\n",
              "      <td>6.949349e-07</td>\n",
              "      <td>0.001849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>0.003538</td>\n",
              "      <td>0.003274</td>\n",
              "      <td>0.003442</td>\n",
              "      <td>0.004543</td>\n",
              "      <td>0.003823</td>\n",
              "      <td>2.493584e-07</td>\n",
              "      <td>0.003724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR(kernel=\"linear\")</th>\n",
              "      <td>0.003114</td>\n",
              "      <td>0.002982</td>\n",
              "      <td>0.003062</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>0.003246</td>\n",
              "      <td>3.004922e-07</td>\n",
              "      <td>0.003342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR(kernel=\"rbf\")</th>\n",
              "      <td>0.003538</td>\n",
              "      <td>0.003274</td>\n",
              "      <td>0.003442</td>\n",
              "      <td>0.004543</td>\n",
              "      <td>0.003823</td>\n",
              "      <td>2.493584e-07</td>\n",
              "      <td>0.003724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              0         1  ...           Var      Mean\n",
              "LinearRegression       0.000509  0.000445  ...  1.855842e-07  0.000707\n",
              "Ridge                  0.000513  0.000450  ...  1.848617e-07  0.000709\n",
              "SGDRegressor           0.001338  0.001136  ...  2.280844e-07  0.001446\n",
              "BayesianRidge          0.000514  0.000451  ...  1.858500e-07  0.000708\n",
              "HuberRegressor         0.000533  0.000456  ...  1.988437e-07  0.000738\n",
              "Lasso                  0.000511  0.000450  ...  1.860553e-07  0.000709\n",
              "BaggingRegressor       0.002236  0.001528  ...  8.098340e-07  0.002313\n",
              "ElasticNet             0.002531  0.001983  ...  8.498229e-07  0.002754\n",
              "RandomForestRegressor  0.001889  0.001432  ...  8.196422e-07  0.002126\n",
              "AdaBoostRegressor      0.001628  0.001251  ...  6.949349e-07  0.001849\n",
              "SVR                    0.003538  0.003274  ...  2.493584e-07  0.003724\n",
              "SVR(kernel=\"linear\")   0.003114  0.002982  ...  3.004922e-07  0.003342\n",
              "SVR(kernel=\"rbf\")      0.003538  0.003274  ...  2.493584e-07  0.003724\n",
              "\n",
              "[13 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJNp0pX6hQTt",
        "outputId": "e3c9248e-b62f-444a-d240-42e1bbe9c34e"
      },
      "source": [
        "clf = RandomForestRegressor()\n",
        "clf = train_model(clf, data_clean, labels_clean)\n",
        "test = pd.read_csv('test_t0.csv')\n",
        "test = remove_id_column(test)\n",
        "predict = clf.predict(test)"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUZnNRg5wmIR",
        "outputId": "981b6c0e-52ba-441a-9719-a19c47cfc324"
      },
      "source": [
        "test_gonderdigim = pd.read_csv('batuyu_yok_ediyorum.csv')\n",
        "predict = make_submission(predict, 'batuyu_yok_eden_bu_muydu.csv')"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batuyu_yok_eden_bu_muydu.csv saved at /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf8vC975xDrj",
        "outputId": "6a157cc7-ac45-4c0c-af55-edbdee31ccac"
      },
      "source": [
        "print(predict.head())\n",
        "print(test_gonderdigim.head())"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    predicted\n",
            "ID           \n",
            "0    0.048802\n",
            "1    0.076645\n",
            "2    0.054947\n",
            "3    0.000000\n",
            "4    0.048802\n",
            "   ID  predicted\n",
            "0   0   0.048603\n",
            "1   1   0.098349\n",
            "2   2   0.181086\n",
            "3   3   0.000000\n",
            "4   4   0.048603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "U9tUTSsXiSo3",
        "outputId": "9d9a88a4-f1d3-49db-92ba-1325dfca469d"
      },
      "source": [
        "make_submission(predict, \"batuyu_yok_ediyorum.csv\")"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adaboostregressor_z_score_st_45.csv saved at /content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.135403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.101400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.199240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.120368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47595</th>\n",
              "      <td>0.145054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47596</th>\n",
              "      <td>0.162142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47597</th>\n",
              "      <td>0.044967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47598</th>\n",
              "      <td>0.046432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47599</th>\n",
              "      <td>0.332748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47600 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted\n",
              "ID              \n",
              "0       0.135403\n",
              "1       0.101400\n",
              "2       0.199240\n",
              "3       0.000000\n",
              "4       0.120368\n",
              "...          ...\n",
              "47595   0.145054\n",
              "47596   0.162142\n",
              "47597   0.044967\n",
              "47598   0.046432\n",
              "47599   0.332748\n",
              "\n",
              "[47600 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfHep8bn2Vh-",
        "outputId": "4ab1ef0a-4f31-40fe-a608-786a3158556a"
      },
      "source": [
        "diff_df = pd.DataFrame(diff)\n",
        "Q1 = diff_df.quantile(0.20)\n",
        "Q3 = diff_df.quantile(0.80)\n",
        "IQR = Q3-Q1\n",
        "print(IQR)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      0.044522\n",
            "1      0.055733\n",
            "2      0.065716\n",
            "3      0.000000\n",
            "4      0.044522\n",
            "         ...   \n",
            "590    0.061825\n",
            "591    0.063336\n",
            "592    0.041889\n",
            "593    0.041889\n",
            "594    0.095796\n",
            "Length: 595, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTyEdvyQhPWR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A458CAWm2riM",
        "outputId": "1e91af91-563a-4777-e6b0-22bb8ff42f44"
      },
      "source": [
        "boston_df_out = diff_df[~((diff_df < (Q1 - 1.5 * IQR)) |(diff_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "boston_df_out.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 595)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCojdUI621Q3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKS2mdY7o3x8"
      },
      "source": [
        "data = X.to_numpy()\n",
        "labels = Y.to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(data)\n",
        "# Apply transform to both the training set and the test set.\n",
        "data = scaler.transform(data)\n",
        "labels = scaler.transform(labels)\n",
        "test = scaler.transform(test)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNVa6n3YoICI"
      },
      "source": [
        "prediction = []\n",
        "for i in range(X.shape[1]):\n",
        "    selectkbest = SelectKBest(f_regression, k=20).fit(data, labels[:, i])\n",
        "    data_new = selectkbest.transform(data)\n",
        "    model = RandomForestRegressor()\n",
        "    model.fit(data_new, labels[:, i])\n",
        "    test_new = selectkbest.transform(test)\n",
        "    prediction.append(model.predict(test_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-DCFVGspiZN",
        "outputId": "a06dfcf9-b555-4b3a-e96c-89bfb048e768"
      },
      "source": [
        "predict = np.asarray(prediction).T\n",
        "predict.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 595)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "6XqlXX_UvDP-",
        "outputId": "f1a99e33-c367-4cd1-d347-ea35fce87a71"
      },
      "source": [
        "make_submission(predict, \"mayali_orumcek_gozu_v2.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mayali_orumcek_gozu_v2.csv saved at /content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.382457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.209713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.508423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.398422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47595</th>\n",
              "      <td>0.539263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47596</th>\n",
              "      <td>0.493942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47597</th>\n",
              "      <td>0.151568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47598</th>\n",
              "      <td>0.157664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47599</th>\n",
              "      <td>0.656358</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47600 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted\n",
              "ID              \n",
              "0       0.382457\n",
              "1       0.209713\n",
              "2       0.508423\n",
              "3       0.000000\n",
              "4       0.398422\n",
              "...          ...\n",
              "47595   0.539263\n",
              "47596   0.493942\n",
              "47597   0.151568\n",
              "47598   0.157664\n",
              "47599   0.656358\n",
              "\n",
              "[47600 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqa9cah6la5q",
        "outputId": "c97cf88a-f33f-4448-b73a-a04c95c104be"
      },
      "source": [
        "train = X.to_numpy()\n",
        "labels = Y.to_numpy()\n",
        "test_data = test.to_numpy()\n",
        "\n",
        "diff = train - labels\n",
        "square = np.square(diff)\n",
        "sum = np.sum(square, 0)\n",
        "threshold = 0.01\n",
        "print(np.where(sum<threshold))\n",
        "for i in np.where(sum<threshold):\n",
        "    train = np.delete(train, i, 1)\n",
        "    test_data = np.delete(test_data, i, 1)\n",
        "print(train.shape)\n",
        "print(test_data.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([  3, 465, 468, 496, 499, 527]),)\n",
            "(150, 589)\n",
            "(80, 589)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imFYh3DUmokM",
        "outputId": "7a6b8fde-662f-4934-a511-685d3e41f9d2"
      },
      "source": [
        "test = data[-15:]\n",
        "test_labels = labels[-15:]\n",
        "train = data[:-15]\n",
        "train_labels = labels[:-15]\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(train)\n",
        "# Apply transform to both the training set and the test set.\n",
        "train = scaler.transform(train)\n",
        "# test_data = scaler.transform(test_data)\n",
        "test = scaler.transform(test)\n",
        "\n",
        "\n",
        "pca = PCA(0.70)\n",
        "pca.fit(train)\n",
        "train = pca.transform(train)\n",
        "# testdata = pca.transform(test_data)\n",
        "test = pca.transform(test)\n",
        "print(train.shape, train_labels.shape)\n",
        "model = MultiOutputRegressor(AdaBoostRegressor())\n",
        "# from xgboost import XGBRFRegressor\n",
        "# model = MultiOutputRegressor(XGBRFRegressor(objective='reg:squarederror', n_estimators=200, verbosity=0))\n",
        "# parameters = {'n_estimators':[1,2000]}\n",
        "# model = RandomForestRegressor(n_estimators=200)\n",
        "# clf = GridSearchCV(model, parameters)\n",
        "# clf.fit(train, train_labels)\n",
        "# model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=34, learning_rate=1.27, max_depth=3))\n",
        "model.fit(train, train_labels)\n",
        "prediction = model.predict(test)\n",
        "print(mean_squared_error(prediction, test_labels))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(126, 20) (126, 595)\n",
            "0.0026902277685429167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-d_gjRSJWu-",
        "outputId": "5215e660-3ef6-4ed8-8f70-8f2064092400"
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv': None,\n",
              " 'error_score': nan,\n",
              " 'estimator': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       max_samples=None, min_impurity_decrease=0.0,\n",
              "                       min_impurity_split=None, min_samples_leaf=1,\n",
              "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
              "                       random_state=None, verbose=0, warm_start=False),\n",
              " 'estimator__bootstrap': True,\n",
              " 'estimator__ccp_alpha': 0.0,\n",
              " 'estimator__criterion': 'mse',\n",
              " 'estimator__max_depth': None,\n",
              " 'estimator__max_features': 'auto',\n",
              " 'estimator__max_leaf_nodes': None,\n",
              " 'estimator__max_samples': None,\n",
              " 'estimator__min_impurity_decrease': 0.0,\n",
              " 'estimator__min_impurity_split': None,\n",
              " 'estimator__min_samples_leaf': 1,\n",
              " 'estimator__min_samples_split': 2,\n",
              " 'estimator__min_weight_fraction_leaf': 0.0,\n",
              " 'estimator__n_estimators': 200,\n",
              " 'estimator__n_jobs': None,\n",
              " 'estimator__oob_score': False,\n",
              " 'estimator__random_state': None,\n",
              " 'estimator__verbose': 0,\n",
              " 'estimator__warm_start': False,\n",
              " 'iid': 'deprecated',\n",
              " 'n_jobs': None,\n",
              " 'param_grid': {'n_estimators': [1, 2000]},\n",
              " 'pre_dispatch': '2*n_jobs',\n",
              " 'refit': True,\n",
              " 'return_train_score': False,\n",
              " 'scoring': None,\n",
              " 'verbose': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bQVZvXTJE7P",
        "outputId": "f4f5f673-ce84-41d9-f9e1-059afdb82b47"
      },
      "source": [
        "test = scaler.transform(test)\n",
        "test = pca.transform(test)\n",
        "prediction = clf.predict(test)\n",
        "print(mean_squared_error(test_labels, prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0024387781369686595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "rzHeW1zKn3pX",
        "outputId": "b106a2d4-647b-48f3-8cab-db5366750374"
      },
      "source": [
        "prediction = model.predict(testdata)\n",
        "make_submission(prediction, \"rf_pca60.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rf_pca60.csv saved at /content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.056785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.091636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.116463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.056785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47595</th>\n",
              "      <td>0.133711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47596</th>\n",
              "      <td>0.131512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47597</th>\n",
              "      <td>0.038767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47598</th>\n",
              "      <td>0.038767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47599</th>\n",
              "      <td>0.316683</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47600 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted\n",
              "ID              \n",
              "0       0.056785\n",
              "1       0.091636\n",
              "2       0.116463\n",
              "3       0.000000\n",
              "4       0.056785\n",
              "...          ...\n",
              "47595   0.133711\n",
              "47596   0.131512\n",
              "47597   0.038767\n",
              "47598   0.038767\n",
              "47599   0.316683\n",
              "\n",
              "[47600 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acbzDCFQmr6a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSbKyO_JiKn-"
      },
      "source": [
        "# pcc_features = []\n",
        "# corr_features = []\n",
        "# corr_matrix = X.corr()\n",
        "\n",
        "# # determining similar (mutually-correlated) features\n",
        "# for i in range(1, len(corr_matrix.columns)):\n",
        "#     for j in range(1, i+1):\n",
        "#         if np.abs(corr_matrix[f\"f{i}\"][f\"f{j}\"]) > 0.75:\n",
        "#             corr_features.append(f\"f{i}\")\n",
        "\n",
        "# corr_matrix = corr_matrix.drop(corr_features)  # eliminating similar features\n",
        "# corr_label = corr_matrix[\"Labels\"].abs()  # taking absolute of correlations\n",
        "\n",
        "# sorted_corr_label = corr_label.sort_values(na_position=\"last\", ascending=False)\n",
        "# feature_names = sorted_corr_label.index\n",
        "\n",
        "# for i in range(1, nof_features + 1): # taking most informative n features\n",
        "#     pcc_features.append(feature_names[i])\n",
        "\n",
        "# print(pcc_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "771e13gDj6Lq",
        "outputId": "b17740c0-379d-421c-ae31-891fbb8de270"
      },
      "source": [
        "corr_matrix.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f4</th>\n",
              "      <th>f466</th>\n",
              "      <th>f469</th>\n",
              "      <th>f497</th>\n",
              "      <th>f500</th>\n",
              "      <th>f528</th>\n",
              "      <th>f595</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.269706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.084309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.176075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.269706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    f4  f466  f469  f497  f500  f528      f595\n",
              "f1 NaN   NaN   NaN   NaN   NaN   NaN -0.269706\n",
              "f2 NaN   NaN   NaN   NaN   NaN   NaN -0.084309\n",
              "f3 NaN   NaN   NaN   NaN   NaN   NaN -0.176075\n",
              "f4 NaN   NaN   NaN   NaN   NaN   NaN       NaN\n",
              "f5 NaN   NaN   NaN   NaN   NaN   NaN -0.269706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHKiWVAdiHup"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "1AY0U4kHgdq-",
        "outputId": "522ebdd6-8aaa-4778-e99e-36ae72ab25a0"
      },
      "source": [
        "model = RandomForestRegressor()\n",
        "selector = RFE(model, n_features_to_select=20)\n",
        "selector = selector.fit(train, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-eeb313f13390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         X, y = check_X_y(X, y, \"csc\", ensure_min_features=2,\n\u001b[0;32m--> 159\u001b[0;31m                          force_all_finite=not tags.get('allow_nan', True))\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m                         dtype=None)\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (135, 595)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8QqXM_7hA1Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xESdWGTuXXZw"
      },
      "source": [
        "def lets_try(train,train_labels,test,test_labels):\n",
        "    results={}\n",
        "    \n",
        "    print(train.shape)\n",
        "    print(test.shape)\n",
        "    print(train_labels.shape)\n",
        "    print(test_labels.shape)\n",
        "    def test_model(clf):\n",
        "\n",
        "        clf.fit(train, train_labels)\n",
        "        test_predict = clf.predict(test)\n",
        "        scores = mean_squared_error(test_labels, test_predict)\n",
        "\n",
        "        return [scores]\n",
        "\n",
        "    clf = linear_model.LinearRegression()\n",
        "    print(f\"Linear Regression = {test_model(clf)}\")\n",
        "    \n",
        "    clf = linear_model.Ridge()\n",
        "    print(f\"Ridge = {test_model(clf)}\")\n",
        "    \n",
        "    # clf = MultiOutputRegressor(SGDRegressor())\n",
        "    # print(f\"SGDRegressor = {test_model(clf)}\")\n",
        "\n",
        "    clf = MultiOutputRegressor(linear_model.BayesianRidge())\n",
        "    print(f\"BayesianRidge = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(linear_model.HuberRegressor())\n",
        "    print(f\"HuberRegressor= {test_model(clf)}\")\n",
        "    \n",
        "    clf = linear_model.Lasso(alpha=1e-4)\n",
        "    print(f\"Lasso = {test_model(clf)}\")\n",
        "        \n",
        "    clf = BaggingRegressor()\n",
        "    print(f\"BaggingRegressor = {test_model(clf)}\")\n",
        "\n",
        "    clf = ElasticNet()\n",
        "    print(f\"ElasticNet = {test_model(clf)}\")\n",
        "    \n",
        "    clf = RandomForestRegressor()\n",
        "    print(f\"RandomForestRegressor= {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(AdaBoostRegressor())\n",
        "    print(f\"AdaBoostRegressor = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(svm.SVR())\n",
        "    print(f\"SVM RBF = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(svm.SVR(kernel=\"linear\"))\n",
        "    print(f\"SVM Linear = {test_model(clf)}\")\n",
        "       \n",
        "    clf = MultiOutputRegressor(svm.SVR(kernel=\"rbf\"))\n",
        "    print(f\"SVM Linear rbf {test_model(clf)}\")\n",
        "\n",
        "\n",
        "# lets_try(train,train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZZfjLREVf-G",
        "outputId": "bf744872-5477-4c32-f44c-52e0fe11ab2f"
      },
      "source": [
        "kf = KFold(n_splits=10)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    train = X[train_index, :]\n",
        "    train_labels = Y[train_index, :]\n",
        "    test = X[test_index, :]\n",
        "    test_labels = Y[test_index, :]\n",
        "\n",
        "    # Fit on training set only.\n",
        "    scaler.fit(train)\n",
        "    # Apply transform to both the training set and the test set.\n",
        "    train = scaler.transform(train)\n",
        "    test = scaler.transform(test)\n",
        "\n",
        "    pca = PCA(0.70)\n",
        "    pca.fit(train)\n",
        "    train = pca.transform(train)\n",
        "    test = pca.transform(test)\n",
        "\n",
        "    lets_try(train,train_labels,test,test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135, 19)\n",
            "(15, 19)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.005802272956797038]\n",
            "Ridge = [0.005799988728181303]\n",
            "BayesianRidge = [0.004297786222005502]\n",
            "HuberRegressor= [0.004622051656589287]\n",
            "Lasso = [0.005790250820408533]\n",
            "BaggingRegressor = [0.004056072586337191]\n",
            "ElasticNet = [0.0030826790406581098]\n",
            "RandomForestRegressor= [0.00402007929036715]\n",
            "AdaBoostRegressor = [0.0041291666017797945]\n",
            "SVM RBF = [0.0054829324623424285]\n",
            "SVM Linear = [0.007069600173376448]\n",
            "SVM Linear rbf [0.0054829324623424285]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.006744191885778283]\n",
            "Ridge = [0.006743680477484871]\n",
            "BayesianRidge = [0.006507214061402251]\n",
            "HuberRegressor= [0.006800372756951189]\n",
            "Lasso = [0.006742680791274501]\n",
            "BaggingRegressor = [0.008102009029265259]\n",
            "ElasticNet = [0.0069362924667603545]\n",
            "RandomForestRegressor= [0.010728668527239145]\n",
            "AdaBoostRegressor = [0.009640671034316697]\n",
            "SVM RBF = [0.007188838358384941]\n",
            "SVM Linear = [0.007198396567356369]\n",
            "SVM Linear rbf [0.007188838358384941]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.0023045183308133764]\n",
            "Ridge = [0.0023041497995984583]\n",
            "BayesianRidge = [0.0021378877788895876]\n",
            "HuberRegressor= [0.0021207545646454214]\n",
            "Lasso = [0.002302697452722897]\n",
            "BaggingRegressor = [0.002598639753050235]\n",
            "ElasticNet = [0.0025102862420139298]\n",
            "RandomForestRegressor= [0.002242842157217008]\n",
            "AdaBoostRegressor = [0.0023012304887634768]\n",
            "SVM RBF = [0.004641813739452005]\n",
            "SVM Linear = [0.00367907916418258]\n",
            "SVM Linear rbf [0.004641813739452005]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.0025639376342007263]\n",
            "Ridge = [0.002563666511163113]\n",
            "BayesianRidge = [0.0024434805608064642]\n",
            "HuberRegressor= [0.002468197582583029]\n",
            "Lasso = [0.0025624369470381076]\n",
            "BaggingRegressor = [0.002487186469989797]\n",
            "ElasticNet = [0.002904297259787476]\n",
            "RandomForestRegressor= [0.002333295561098554]\n",
            "AdaBoostRegressor = [0.0025187103614842717]\n",
            "SVM RBF = [0.004504221270852039]\n",
            "SVM Linear = [0.0038039811351258303]\n",
            "SVM Linear rbf [0.004504221270852039]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.005164427021598518]\n",
            "Ridge = [0.005164167810874289]\n",
            "BayesianRidge = [0.005153677465195344]\n",
            "HuberRegressor= [0.005226145178489968]\n",
            "Lasso = [0.005164081922971847]\n",
            "BaggingRegressor = [0.005703330385007766]\n",
            "ElasticNet = [0.005776121174494068]\n",
            "RandomForestRegressor= [0.005401241834928647]\n",
            "AdaBoostRegressor = [0.005330574257363599]\n",
            "SVM RBF = [0.006677056534854889]\n",
            "SVM Linear = [0.0062700324730901634]\n",
            "SVM Linear rbf [0.006677056534854889]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.0020036552371676883]\n",
            "Ridge = [0.0020033225996146883]\n",
            "BayesianRidge = [0.0018156061980202094]\n",
            "HuberRegressor= [0.0017102318993381855]\n",
            "Lasso = [0.0020020438619769215]\n",
            "BaggingRegressor = [0.0018897397444012892]\n",
            "ElasticNet = [0.002194761461803483]\n",
            "RandomForestRegressor= [0.0017733194673465297]\n",
            "AdaBoostRegressor = [0.0019269472979016888]\n",
            "SVM RBF = [0.0038769952379162417]\n",
            "SVM Linear = [0.0033247080027624287]\n",
            "SVM Linear rbf [0.0038769952379162417]\n",
            "(135, 15)\n",
            "(15, 15)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.002786927428653145]\n",
            "Ridge = [0.002786718118785138]\n",
            "BayesianRidge = [0.0026657877284159037]\n",
            "HuberRegressor= [0.00269085722337065]\n",
            "Lasso = [0.0027858243055081905]\n",
            "BaggingRegressor = [0.002955599320451397]\n",
            "ElasticNet = [0.0028839527435591213]\n",
            "RandomForestRegressor= [0.002702839123732035]\n",
            "AdaBoostRegressor = [0.002768456849174212]\n",
            "SVM RBF = [0.004920677326775243]\n",
            "SVM Linear = [0.0038845834542473538]\n",
            "SVM Linear rbf [0.004920677326775243]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.0052766083802658495]\n",
            "Ridge = [0.005275847989638481]\n",
            "BayesianRidge = [0.004820034635472762]\n",
            "HuberRegressor= [0.005026180298915299]\n",
            "Lasso = [0.005273642590599138]\n",
            "BaggingRegressor = [0.004758714351386203]\n",
            "ElasticNet = [0.004821847827563947]\n",
            "RandomForestRegressor= [0.0045268301422334905]\n",
            "AdaBoostRegressor = [0.0046410166751561805]\n",
            "SVM RBF = [0.005492814286647762]\n",
            "SVM Linear = [0.00594884576679866]\n",
            "SVM Linear rbf [0.005492814286647762]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.010119589993062863]\n",
            "Ridge = [0.010119753227389148]\n",
            "BayesianRidge = [0.010289064935715768]\n",
            "HuberRegressor= [0.010196346157144919]\n",
            "Lasso = [0.010120091934235345]\n",
            "BaggingRegressor = [0.010162610548886604]\n",
            "ElasticNet = [0.011354407955110935]\n",
            "RandomForestRegressor= [0.009976735097034919]\n",
            "AdaBoostRegressor = [0.010271722899001794]\n",
            "SVM RBF = [0.011318486537443332]\n",
            "SVM Linear = [0.011190860576632366]\n",
            "SVM Linear rbf [0.011318486537443332]\n",
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.002596325787652625]\n",
            "Ridge = [0.0025961320992643933]\n",
            "BayesianRidge = [0.0025376615663518782]\n",
            "HuberRegressor= [0.002633996183132533]\n",
            "Lasso = [0.0025950992079001494]\n",
            "BaggingRegressor = [0.002507620790240666]\n",
            "ElasticNet = [0.0029951336319722984]\n",
            "RandomForestRegressor= [0.002490842896038554]\n",
            "AdaBoostRegressor = [0.0026133376407376676]\n",
            "SVM RBF = [0.004267637341080629]\n",
            "SVM Linear = [0.004026512971278571]\n",
            "SVM Linear rbf [0.004267637341080629]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzvkVXXnPVH8"
      },
      "source": [
        "test = data[-15:]\n",
        "test_labels = labels[-15:]\n",
        "train = data[:-15]\n",
        "train_labels = labels[:-15]\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(train)\n",
        "# Apply transform to both the training set and the test set.\n",
        "train = scaler.transform(train)\n",
        "test = scaler.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ZPy94Rl5PYl_",
        "outputId": "5116e792-5551-4bea-cc84-ef76f3382173"
      },
      "source": [
        "train_new = SelectKBest(f_regression, k=20).fit_transform(train, train_labels)\n",
        "\n",
        "\n",
        "pca = PCA(0.70)\n",
        "pca.fit(train)\n",
        "train = pca.transform(train)\n",
        "test = pca.transform(test)\n",
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-32b0e7286904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pca = PCA(0.70)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# pca.fit(train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/_univariate_selection.py\u001b[0m in \u001b[0;36mf_regression\u001b[0;34m(X, y, center)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m                         dtype=None)\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (135, 595)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4nU-NSTPbLQ"
      },
      "source": [
        " from xgboost import XGBRFRegressor\n",
        " model = MultiOutputRegressor(XGBRFRegressor(n_estimators=200, verbosity=0, \n",
        "                                             subsmaple=0.4, colsample_bynode=0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3TzKcccPwaZ",
        "outputId": "ce03154f-3b99-4bae-b416-3237ff9496a4"
      },
      "source": [
        "model.fit(train,train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=XGBRFRegressor(base_score=0.5,\n",
              "                                              colsample_bylevel=1,\n",
              "                                              colsample_bynode=0.2,\n",
              "                                              colsample_bytree=1, gamma=0,\n",
              "                                              learning_rate=1, max_delta_step=0,\n",
              "                                              max_depth=3, min_child_weight=1,\n",
              "                                              missing=None, n_estimators=200,\n",
              "                                              n_jobs=1, nthread=None,\n",
              "                                              objective='reg:linear',\n",
              "                                              random_state=0, reg_alpha=0,\n",
              "                                              reg_lambda=1, scale_pos_weight=1,\n",
              "                                              seed=None, silent=None,\n",
              "                                              subsample=0.8, subsmaple=0.4,\n",
              "                                              verbosity=0),\n",
              "                     n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ByezzRjP2Fh",
        "outputId": "9e571b35-9c5e-4e71-b990-9b8b3074609a"
      },
      "source": [
        "prediction = model.predict(test)\n",
        "score = mean_squared_error(prediction, test_labels)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0028515496249414737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPSv76x2QWci",
        "outputId": "25c0f7ee-edea-4e7a-94d8-486e63d51914"
      },
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "\n",
        "\n",
        "lets_try(train,train_labels,test,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 595)\n",
            "(15, 595)\n",
            "Linear Regression = [0.0025963257876526254]\n",
            "Ridge = [0.0025961320992643937]\n",
            "SGDRegressor = [460818299441.5089]\n",
            "BayesianRidge = [0.0025376615663518787]\n",
            "HuberRegressor= [0.0026339961831321882]\n",
            "Lasso = [0.0025950992079001494]\n",
            "BaggingRegressor = [0.0028120621037918438]\n",
            "ElasticNet = [0.0029951336319722984]\n",
            "RandomForestRegressor= [0.0025045804372139393]\n",
            "AdaBoostRegressor = [0.0026053968063475216]\n",
            "SVM RBF = [0.004267637341080627]\n",
            "SVM Linear = [0.004026565252999204]\n",
            "SVM Linear rbf [0.004267637341080627]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "LRQJFrz3GTcA",
        "outputId": "e7778181-7059-4aaf-b4fe-c3e69ba914a7"
      },
      "source": [
        "test = data[-15:]\n",
        "test_labels = labels[-15:]\n",
        "train = data[:-1b5]\n",
        "train_labels = labels[:-15]\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(train)\n",
        "# Apply transform to both the training set and the test set.\n",
        "train = scaler.transform(train)\n",
        "test = scaler.transform(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 596)\n",
            "(150, 596)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>...</th>\n",
              "      <th>f556</th>\n",
              "      <th>f557</th>\n",
              "      <th>f558</th>\n",
              "      <th>f559</th>\n",
              "      <th>f560</th>\n",
              "      <th>f561</th>\n",
              "      <th>f562</th>\n",
              "      <th>f563</th>\n",
              "      <th>f564</th>\n",
              "      <th>f565</th>\n",
              "      <th>f566</th>\n",
              "      <th>f567</th>\n",
              "      <th>f568</th>\n",
              "      <th>f569</th>\n",
              "      <th>f570</th>\n",
              "      <th>f571</th>\n",
              "      <th>f572</th>\n",
              "      <th>f573</th>\n",
              "      <th>f574</th>\n",
              "      <th>f575</th>\n",
              "      <th>f576</th>\n",
              "      <th>f577</th>\n",
              "      <th>f578</th>\n",
              "      <th>f579</th>\n",
              "      <th>f580</th>\n",
              "      <th>f581</th>\n",
              "      <th>f582</th>\n",
              "      <th>f583</th>\n",
              "      <th>f584</th>\n",
              "      <th>f585</th>\n",
              "      <th>f586</th>\n",
              "      <th>f587</th>\n",
              "      <th>f588</th>\n",
              "      <th>f589</th>\n",
              "      <th>f590</th>\n",
              "      <th>f591</th>\n",
              "      <th>f592</th>\n",
              "      <th>f593</th>\n",
              "      <th>f594</th>\n",
              "      <th>f595</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.193382</td>\n",
              "      <td>0.096121</td>\n",
              "      <td>0.289502</td>\n",
              "      <td>0</td>\n",
              "      <td>0.193382</td>\n",
              "      <td>0.096121</td>\n",
              "      <td>0.273247</td>\n",
              "      <td>0.466629</td>\n",
              "      <td>0.177126</td>\n",
              "      <td>0.273247</td>\n",
              "      <td>0.383924</td>\n",
              "      <td>0.577305</td>\n",
              "      <td>0.287803</td>\n",
              "      <td>0.383924</td>\n",
              "      <td>0.110677</td>\n",
              "      <td>0.279031</td>\n",
              "      <td>0.472412</td>\n",
              "      <td>0.182910</td>\n",
              "      <td>0.279031</td>\n",
              "      <td>0.005784</td>\n",
              "      <td>0.104893</td>\n",
              "      <td>0.110154</td>\n",
              "      <td>0.303536</td>\n",
              "      <td>0.014033</td>\n",
              "      <td>0.110154</td>\n",
              "      <td>0.163093</td>\n",
              "      <td>0.273770</td>\n",
              "      <td>0.168877</td>\n",
              "      <td>0.656734</td>\n",
              "      <td>0.850116</td>\n",
              "      <td>0.560613</td>\n",
              "      <td>0.656734</td>\n",
              "      <td>0.383487</td>\n",
              "      <td>0.272810</td>\n",
              "      <td>0.377703</td>\n",
              "      <td>0.546580</td>\n",
              "      <td>0.048374</td>\n",
              "      <td>0.145008</td>\n",
              "      <td>0.144495</td>\n",
              "      <td>0.048374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.126646</td>\n",
              "      <td>0.048892</td>\n",
              "      <td>0.193999</td>\n",
              "      <td>0.091083</td>\n",
              "      <td>0.063588</td>\n",
              "      <td>0.063588</td>\n",
              "      <td>0.015484</td>\n",
              "      <td>0.208866</td>\n",
              "      <td>0.080636</td>\n",
              "      <td>0.015484</td>\n",
              "      <td>0.257763</td>\n",
              "      <td>0.368439</td>\n",
              "      <td>0.263546</td>\n",
              "      <td>0.094670</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>0.063858</td>\n",
              "      <td>0.251580</td>\n",
              "      <td>0.445395</td>\n",
              "      <td>0.343711</td>\n",
              "      <td>0.533262</td>\n",
              "      <td>0.209793</td>\n",
              "      <td>0.433611</td>\n",
              "      <td>0.070879</td>\n",
              "      <td>0.055528</td>\n",
              "      <td>0.217489</td>\n",
              "      <td>0.052125</td>\n",
              "      <td>0.199823</td>\n",
              "      <td>0.115555</td>\n",
              "      <td>0.533486</td>\n",
              "      <td>0.012033</td>\n",
              "      <td>0.110908</td>\n",
              "      <td>0.193465</td>\n",
              "      <td>0.186630</td>\n",
              "      <td>0.174750</td>\n",
              "      <td>0.096996</td>\n",
              "      <td>0.242103</td>\n",
              "      <td>0.042979</td>\n",
              "      <td>0.015484</td>\n",
              "      <td>0.015484</td>\n",
              "      <td>0.048103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.014410</td>\n",
              "      <td>0.064584</td>\n",
              "      <td>0.050174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014410</td>\n",
              "      <td>0.064584</td>\n",
              "      <td>0.115367</td>\n",
              "      <td>0.100957</td>\n",
              "      <td>0.050783</td>\n",
              "      <td>0.115367</td>\n",
              "      <td>0.280751</td>\n",
              "      <td>0.266341</td>\n",
              "      <td>0.216167</td>\n",
              "      <td>0.280751</td>\n",
              "      <td>0.165384</td>\n",
              "      <td>0.133898</td>\n",
              "      <td>0.119488</td>\n",
              "      <td>0.069314</td>\n",
              "      <td>0.133898</td>\n",
              "      <td>0.018531</td>\n",
              "      <td>0.146853</td>\n",
              "      <td>0.114678</td>\n",
              "      <td>0.100268</td>\n",
              "      <td>0.050094</td>\n",
              "      <td>0.114678</td>\n",
              "      <td>0.000689</td>\n",
              "      <td>0.166073</td>\n",
              "      <td>0.019220</td>\n",
              "      <td>0.131172</td>\n",
              "      <td>0.116761</td>\n",
              "      <td>0.066588</td>\n",
              "      <td>0.131172</td>\n",
              "      <td>0.015805</td>\n",
              "      <td>0.149580</td>\n",
              "      <td>0.002727</td>\n",
              "      <td>0.016494</td>\n",
              "      <td>0.065569</td>\n",
              "      <td>0.051158</td>\n",
              "      <td>0.000985</td>\n",
              "      <td>0.065569</td>\n",
              "      <td>...</td>\n",
              "      <td>0.131344</td>\n",
              "      <td>0.142796</td>\n",
              "      <td>0.153824</td>\n",
              "      <td>0.143518</td>\n",
              "      <td>0.229512</td>\n",
              "      <td>0.229512</td>\n",
              "      <td>0.013585</td>\n",
              "      <td>0.027995</td>\n",
              "      <td>0.078169</td>\n",
              "      <td>0.013585</td>\n",
              "      <td>0.128952</td>\n",
              "      <td>0.294336</td>\n",
              "      <td>0.147483</td>\n",
              "      <td>0.128263</td>\n",
              "      <td>0.144757</td>\n",
              "      <td>0.079154</td>\n",
              "      <td>0.139870</td>\n",
              "      <td>0.143458</td>\n",
              "      <td>0.182415</td>\n",
              "      <td>0.120655</td>\n",
              "      <td>0.185169</td>\n",
              "      <td>0.062271</td>\n",
              "      <td>0.096190</td>\n",
              "      <td>0.112874</td>\n",
              "      <td>0.141057</td>\n",
              "      <td>0.152346</td>\n",
              "      <td>0.014494</td>\n",
              "      <td>0.144452</td>\n",
              "      <td>0.025750</td>\n",
              "      <td>0.086677</td>\n",
              "      <td>0.101471</td>\n",
              "      <td>0.028694</td>\n",
              "      <td>0.187073</td>\n",
              "      <td>0.111753</td>\n",
              "      <td>0.100301</td>\n",
              "      <td>0.089273</td>\n",
              "      <td>0.099579</td>\n",
              "      <td>0.013585</td>\n",
              "      <td>0.013585</td>\n",
              "      <td>0.243097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.070879</td>\n",
              "      <td>0.077238</td>\n",
              "      <td>0.148117</td>\n",
              "      <td>0</td>\n",
              "      <td>0.070879</td>\n",
              "      <td>0.077238</td>\n",
              "      <td>0.162528</td>\n",
              "      <td>0.233407</td>\n",
              "      <td>0.085291</td>\n",
              "      <td>0.162528</td>\n",
              "      <td>0.086521</td>\n",
              "      <td>0.157399</td>\n",
              "      <td>0.009283</td>\n",
              "      <td>0.086521</td>\n",
              "      <td>0.076008</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.224879</td>\n",
              "      <td>0.076762</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.008529</td>\n",
              "      <td>0.067479</td>\n",
              "      <td>0.149078</td>\n",
              "      <td>0.219956</td>\n",
              "      <td>0.071840</td>\n",
              "      <td>0.149078</td>\n",
              "      <td>0.013451</td>\n",
              "      <td>0.062557</td>\n",
              "      <td>0.004922</td>\n",
              "      <td>0.197996</td>\n",
              "      <td>0.268875</td>\n",
              "      <td>0.120758</td>\n",
              "      <td>0.197996</td>\n",
              "      <td>0.035468</td>\n",
              "      <td>0.111476</td>\n",
              "      <td>0.043997</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.074722</td>\n",
              "      <td>0.145600</td>\n",
              "      <td>0.002516</td>\n",
              "      <td>0.074722</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012306</td>\n",
              "      <td>0.046075</td>\n",
              "      <td>0.071845</td>\n",
              "      <td>0.042282</td>\n",
              "      <td>0.172846</td>\n",
              "      <td>0.172846</td>\n",
              "      <td>0.046046</td>\n",
              "      <td>0.116925</td>\n",
              "      <td>0.031192</td>\n",
              "      <td>0.046046</td>\n",
              "      <td>0.116482</td>\n",
              "      <td>0.040474</td>\n",
              "      <td>0.107954</td>\n",
              "      <td>0.103031</td>\n",
              "      <td>0.151950</td>\n",
              "      <td>0.028675</td>\n",
              "      <td>0.122083</td>\n",
              "      <td>0.183384</td>\n",
              "      <td>0.183365</td>\n",
              "      <td>0.068136</td>\n",
              "      <td>0.083248</td>\n",
              "      <td>0.091681</td>\n",
              "      <td>0.087642</td>\n",
              "      <td>0.117377</td>\n",
              "      <td>0.190595</td>\n",
              "      <td>0.080120</td>\n",
              "      <td>0.082894</td>\n",
              "      <td>0.108819</td>\n",
              "      <td>0.072999</td>\n",
              "      <td>0.055021</td>\n",
              "      <td>0.085059</td>\n",
              "      <td>0.160802</td>\n",
              "      <td>0.142508</td>\n",
              "      <td>0.114494</td>\n",
              "      <td>0.080725</td>\n",
              "      <td>0.054955</td>\n",
              "      <td>0.084518</td>\n",
              "      <td>0.046046</td>\n",
              "      <td>0.046046</td>\n",
              "      <td>0.126800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.053557</td>\n",
              "      <td>0.065708</td>\n",
              "      <td>0</td>\n",
              "      <td>0.012150</td>\n",
              "      <td>0.053557</td>\n",
              "      <td>0.135480</td>\n",
              "      <td>0.147630</td>\n",
              "      <td>0.081922</td>\n",
              "      <td>0.135480</td>\n",
              "      <td>0.065623</td>\n",
              "      <td>0.077774</td>\n",
              "      <td>0.012066</td>\n",
              "      <td>0.065623</td>\n",
              "      <td>0.069856</td>\n",
              "      <td>0.150656</td>\n",
              "      <td>0.162806</td>\n",
              "      <td>0.097099</td>\n",
              "      <td>0.150656</td>\n",
              "      <td>0.015176</td>\n",
              "      <td>0.085032</td>\n",
              "      <td>0.105734</td>\n",
              "      <td>0.117884</td>\n",
              "      <td>0.052177</td>\n",
              "      <td>0.105734</td>\n",
              "      <td>0.029746</td>\n",
              "      <td>0.040111</td>\n",
              "      <td>0.044922</td>\n",
              "      <td>0.126453</td>\n",
              "      <td>0.138604</td>\n",
              "      <td>0.072896</td>\n",
              "      <td>0.126453</td>\n",
              "      <td>0.009026</td>\n",
              "      <td>0.060830</td>\n",
              "      <td>0.024202</td>\n",
              "      <td>0.020719</td>\n",
              "      <td>0.071057</td>\n",
              "      <td>0.058907</td>\n",
              "      <td>0.124615</td>\n",
              "      <td>0.071057</td>\n",
              "      <td>...</td>\n",
              "      <td>0.124101</td>\n",
              "      <td>0.156046</td>\n",
              "      <td>0.150542</td>\n",
              "      <td>0.138081</td>\n",
              "      <td>0.225818</td>\n",
              "      <td>0.225818</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.019580</td>\n",
              "      <td>0.046128</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.128050</td>\n",
              "      <td>0.058194</td>\n",
              "      <td>0.143226</td>\n",
              "      <td>0.098304</td>\n",
              "      <td>0.119024</td>\n",
              "      <td>0.078487</td>\n",
              "      <td>0.101074</td>\n",
              "      <td>0.116838</td>\n",
              "      <td>0.134783</td>\n",
              "      <td>0.144918</td>\n",
              "      <td>0.126458</td>\n",
              "      <td>0.099879</td>\n",
              "      <td>0.075145</td>\n",
              "      <td>0.101797</td>\n",
              "      <td>0.167031</td>\n",
              "      <td>0.028526</td>\n",
              "      <td>0.083871</td>\n",
              "      <td>0.105492</td>\n",
              "      <td>0.008554</td>\n",
              "      <td>0.062910</td>\n",
              "      <td>0.066011</td>\n",
              "      <td>0.034460</td>\n",
              "      <td>0.122039</td>\n",
              "      <td>0.094287</td>\n",
              "      <td>0.062342</td>\n",
              "      <td>0.067846</td>\n",
              "      <td>0.080307</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.218388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.035510</td>\n",
              "      <td>0.072512</td>\n",
              "      <td>0.037002</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035510</td>\n",
              "      <td>0.072512</td>\n",
              "      <td>0.056819</td>\n",
              "      <td>0.021309</td>\n",
              "      <td>0.015693</td>\n",
              "      <td>0.056819</td>\n",
              "      <td>0.092735</td>\n",
              "      <td>0.057225</td>\n",
              "      <td>0.020223</td>\n",
              "      <td>0.092735</td>\n",
              "      <td>0.035916</td>\n",
              "      <td>0.154670</td>\n",
              "      <td>0.119161</td>\n",
              "      <td>0.082158</td>\n",
              "      <td>0.154670</td>\n",
              "      <td>0.097851</td>\n",
              "      <td>0.061935</td>\n",
              "      <td>0.147432</td>\n",
              "      <td>0.111922</td>\n",
              "      <td>0.074919</td>\n",
              "      <td>0.147432</td>\n",
              "      <td>0.090612</td>\n",
              "      <td>0.054697</td>\n",
              "      <td>0.007239</td>\n",
              "      <td>0.216227</td>\n",
              "      <td>0.180718</td>\n",
              "      <td>0.143715</td>\n",
              "      <td>0.216227</td>\n",
              "      <td>0.159408</td>\n",
              "      <td>0.123492</td>\n",
              "      <td>0.061557</td>\n",
              "      <td>0.068796</td>\n",
              "      <td>0.038396</td>\n",
              "      <td>0.002886</td>\n",
              "      <td>0.034116</td>\n",
              "      <td>0.038396</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136243</td>\n",
              "      <td>0.151124</td>\n",
              "      <td>0.122952</td>\n",
              "      <td>0.177226</td>\n",
              "      <td>0.250665</td>\n",
              "      <td>0.250665</td>\n",
              "      <td>0.017878</td>\n",
              "      <td>0.017631</td>\n",
              "      <td>0.054634</td>\n",
              "      <td>0.017878</td>\n",
              "      <td>0.038941</td>\n",
              "      <td>0.074857</td>\n",
              "      <td>0.136792</td>\n",
              "      <td>0.129553</td>\n",
              "      <td>0.198349</td>\n",
              "      <td>0.020518</td>\n",
              "      <td>0.154999</td>\n",
              "      <td>0.109175</td>\n",
              "      <td>0.104394</td>\n",
              "      <td>0.120631</td>\n",
              "      <td>0.163377</td>\n",
              "      <td>0.066896</td>\n",
              "      <td>0.080816</td>\n",
              "      <td>0.108183</td>\n",
              "      <td>0.137156</td>\n",
              "      <td>0.111283</td>\n",
              "      <td>0.098557</td>\n",
              "      <td>0.122693</td>\n",
              "      <td>0.014264</td>\n",
              "      <td>0.014730</td>\n",
              "      <td>0.098395</td>\n",
              "      <td>0.117918</td>\n",
              "      <td>0.121873</td>\n",
              "      <td>0.096543</td>\n",
              "      <td>0.081662</td>\n",
              "      <td>0.109835</td>\n",
              "      <td>0.055561</td>\n",
              "      <td>0.017878</td>\n",
              "      <td>0.017878</td>\n",
              "      <td>0.232787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 595 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         f1        f2        f3  f4  ...      f592      f593      f594      f595\n",
              "0  0.193382  0.096121  0.289502   0  ...  0.042979  0.015484  0.015484  0.048103\n",
              "1  0.014410  0.064584  0.050174   0  ...  0.099579  0.013585  0.013585  0.243097\n",
              "2  0.070879  0.077238  0.148117   0  ...  0.084518  0.046046  0.046046  0.126800\n",
              "3  0.012150  0.053557  0.065708   0  ...  0.080307  0.007430  0.007430  0.218388\n",
              "4  0.035510  0.072512  0.037002   0  ...  0.055561  0.017878  0.017878  0.232787\n",
              "\n",
              "[5 rows x 595 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH12ac0mOInu",
        "outputId": "2ddb8ddc-c192-4ffc-8b92-7f5211dc83c4"
      },
      "source": [
        "type(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "GKCG2GeBN-3U",
        "outputId": "aa7c1aec-1d74-402e-a4e6-72c9a3d7b631"
      },
      "source": [
        "label = label.drop(\"ID\",1)\n",
        "label.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>...</th>\n",
              "      <th>f556</th>\n",
              "      <th>f557</th>\n",
              "      <th>f558</th>\n",
              "      <th>f559</th>\n",
              "      <th>f560</th>\n",
              "      <th>f561</th>\n",
              "      <th>f562</th>\n",
              "      <th>f563</th>\n",
              "      <th>f564</th>\n",
              "      <th>f565</th>\n",
              "      <th>f566</th>\n",
              "      <th>f567</th>\n",
              "      <th>f568</th>\n",
              "      <th>f569</th>\n",
              "      <th>f570</th>\n",
              "      <th>f571</th>\n",
              "      <th>f572</th>\n",
              "      <th>f573</th>\n",
              "      <th>f574</th>\n",
              "      <th>f575</th>\n",
              "      <th>f576</th>\n",
              "      <th>f577</th>\n",
              "      <th>f578</th>\n",
              "      <th>f579</th>\n",
              "      <th>f580</th>\n",
              "      <th>f581</th>\n",
              "      <th>f582</th>\n",
              "      <th>f583</th>\n",
              "      <th>f584</th>\n",
              "      <th>f585</th>\n",
              "      <th>f586</th>\n",
              "      <th>f587</th>\n",
              "      <th>f588</th>\n",
              "      <th>f589</th>\n",
              "      <th>f590</th>\n",
              "      <th>f591</th>\n",
              "      <th>f592</th>\n",
              "      <th>f593</th>\n",
              "      <th>f594</th>\n",
              "      <th>f595</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.100531</td>\n",
              "      <td>0.032178</td>\n",
              "      <td>0.132709</td>\n",
              "      <td>0</td>\n",
              "      <td>0.100531</td>\n",
              "      <td>0.032178</td>\n",
              "      <td>0.155462</td>\n",
              "      <td>0.255994</td>\n",
              "      <td>0.123285</td>\n",
              "      <td>0.155462</td>\n",
              "      <td>0.346908</td>\n",
              "      <td>0.447440</td>\n",
              "      <td>0.314730</td>\n",
              "      <td>0.346908</td>\n",
              "      <td>0.191446</td>\n",
              "      <td>0.144941</td>\n",
              "      <td>0.245472</td>\n",
              "      <td>0.112763</td>\n",
              "      <td>0.144941</td>\n",
              "      <td>0.010521</td>\n",
              "      <td>0.201967</td>\n",
              "      <td>0.111707</td>\n",
              "      <td>0.212238</td>\n",
              "      <td>0.079529</td>\n",
              "      <td>0.111707</td>\n",
              "      <td>0.043756</td>\n",
              "      <td>0.235201</td>\n",
              "      <td>0.033234</td>\n",
              "      <td>0.113329</td>\n",
              "      <td>0.213860</td>\n",
              "      <td>0.081151</td>\n",
              "      <td>0.113329</td>\n",
              "      <td>0.042133</td>\n",
              "      <td>0.233579</td>\n",
              "      <td>0.031612</td>\n",
              "      <td>0.001622</td>\n",
              "      <td>0.006050</td>\n",
              "      <td>0.106581</td>\n",
              "      <td>0.026128</td>\n",
              "      <td>0.006050</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008971</td>\n",
              "      <td>0.065154</td>\n",
              "      <td>0.060051</td>\n",
              "      <td>0.078424</td>\n",
              "      <td>0.162326</td>\n",
              "      <td>0.162326</td>\n",
              "      <td>0.055889</td>\n",
              "      <td>0.044643</td>\n",
              "      <td>0.088066</td>\n",
              "      <td>0.055889</td>\n",
              "      <td>0.211351</td>\n",
              "      <td>0.402797</td>\n",
              "      <td>0.200830</td>\n",
              "      <td>0.167595</td>\n",
              "      <td>0.169218</td>\n",
              "      <td>0.061939</td>\n",
              "      <td>0.196242</td>\n",
              "      <td>0.228053</td>\n",
              "      <td>0.214949</td>\n",
              "      <td>0.199267</td>\n",
              "      <td>0.341571</td>\n",
              "      <td>0.170295</td>\n",
              "      <td>0.147523</td>\n",
              "      <td>0.154134</td>\n",
              "      <td>0.232804</td>\n",
              "      <td>0.179231</td>\n",
              "      <td>0.014141</td>\n",
              "      <td>0.200908</td>\n",
              "      <td>0.054104</td>\n",
              "      <td>0.130524</td>\n",
              "      <td>0.173879</td>\n",
              "      <td>0.241906</td>\n",
              "      <td>0.198942</td>\n",
              "      <td>0.209243</td>\n",
              "      <td>0.153060</td>\n",
              "      <td>0.158163</td>\n",
              "      <td>0.139791</td>\n",
              "      <td>0.055889</td>\n",
              "      <td>0.055889</td>\n",
              "      <td>0.218214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.014826</td>\n",
              "      <td>0.071366</td>\n",
              "      <td>0.056540</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014826</td>\n",
              "      <td>0.071366</td>\n",
              "      <td>0.125061</td>\n",
              "      <td>0.110234</td>\n",
              "      <td>0.053695</td>\n",
              "      <td>0.125061</td>\n",
              "      <td>0.253270</td>\n",
              "      <td>0.238443</td>\n",
              "      <td>0.181904</td>\n",
              "      <td>0.253270</td>\n",
              "      <td>0.128209</td>\n",
              "      <td>0.166416</td>\n",
              "      <td>0.151589</td>\n",
              "      <td>0.095049</td>\n",
              "      <td>0.166416</td>\n",
              "      <td>0.041355</td>\n",
              "      <td>0.086854</td>\n",
              "      <td>0.113256</td>\n",
              "      <td>0.098430</td>\n",
              "      <td>0.041890</td>\n",
              "      <td>0.113256</td>\n",
              "      <td>0.011805</td>\n",
              "      <td>0.140014</td>\n",
              "      <td>0.053159</td>\n",
              "      <td>0.210117</td>\n",
              "      <td>0.195291</td>\n",
              "      <td>0.138751</td>\n",
              "      <td>0.210117</td>\n",
              "      <td>0.085056</td>\n",
              "      <td>0.043153</td>\n",
              "      <td>0.043702</td>\n",
              "      <td>0.096861</td>\n",
              "      <td>0.039016</td>\n",
              "      <td>0.024189</td>\n",
              "      <td>0.032350</td>\n",
              "      <td>0.039016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101029</td>\n",
              "      <td>0.102435</td>\n",
              "      <td>0.130848</td>\n",
              "      <td>0.165909</td>\n",
              "      <td>0.213594</td>\n",
              "      <td>0.213594</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.023447</td>\n",
              "      <td>0.079987</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.133682</td>\n",
              "      <td>0.261891</td>\n",
              "      <td>0.175036</td>\n",
              "      <td>0.121877</td>\n",
              "      <td>0.218738</td>\n",
              "      <td>0.047636</td>\n",
              "      <td>0.126726</td>\n",
              "      <td>0.130521</td>\n",
              "      <td>0.147347</td>\n",
              "      <td>0.221152</td>\n",
              "      <td>0.160091</td>\n",
              "      <td>0.076162</td>\n",
              "      <td>0.064230</td>\n",
              "      <td>0.115305</td>\n",
              "      <td>0.140508</td>\n",
              "      <td>0.144069</td>\n",
              "      <td>0.009418</td>\n",
              "      <td>0.138678</td>\n",
              "      <td>0.043492</td>\n",
              "      <td>0.063972</td>\n",
              "      <td>0.064415</td>\n",
              "      <td>0.077555</td>\n",
              "      <td>0.153872</td>\n",
              "      <td>0.121185</td>\n",
              "      <td>0.119779</td>\n",
              "      <td>0.091366</td>\n",
              "      <td>0.056305</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.222214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.097006</td>\n",
              "      <td>0.099051</td>\n",
              "      <td>0.196056</td>\n",
              "      <td>0</td>\n",
              "      <td>0.097006</td>\n",
              "      <td>0.099051</td>\n",
              "      <td>0.197889</td>\n",
              "      <td>0.294895</td>\n",
              "      <td>0.098839</td>\n",
              "      <td>0.197889</td>\n",
              "      <td>0.323073</td>\n",
              "      <td>0.420079</td>\n",
              "      <td>0.224022</td>\n",
              "      <td>0.323073</td>\n",
              "      <td>0.125184</td>\n",
              "      <td>0.186627</td>\n",
              "      <td>0.283633</td>\n",
              "      <td>0.087576</td>\n",
              "      <td>0.186627</td>\n",
              "      <td>0.011262</td>\n",
              "      <td>0.136446</td>\n",
              "      <td>0.130447</td>\n",
              "      <td>0.227452</td>\n",
              "      <td>0.031396</td>\n",
              "      <td>0.130447</td>\n",
              "      <td>0.067443</td>\n",
              "      <td>0.192626</td>\n",
              "      <td>0.056181</td>\n",
              "      <td>0.218066</td>\n",
              "      <td>0.315072</td>\n",
              "      <td>0.119016</td>\n",
              "      <td>0.218066</td>\n",
              "      <td>0.020177</td>\n",
              "      <td>0.105007</td>\n",
              "      <td>0.031439</td>\n",
              "      <td>0.087620</td>\n",
              "      <td>0.038044</td>\n",
              "      <td>0.135050</td>\n",
              "      <td>0.061006</td>\n",
              "      <td>0.038044</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>0.006360</td>\n",
              "      <td>0.006158</td>\n",
              "      <td>0.033650</td>\n",
              "      <td>0.127929</td>\n",
              "      <td>0.127929</td>\n",
              "      <td>0.043688</td>\n",
              "      <td>0.140693</td>\n",
              "      <td>0.055363</td>\n",
              "      <td>0.043688</td>\n",
              "      <td>0.154202</td>\n",
              "      <td>0.279385</td>\n",
              "      <td>0.142940</td>\n",
              "      <td>0.086759</td>\n",
              "      <td>0.174379</td>\n",
              "      <td>0.005643</td>\n",
              "      <td>0.102093</td>\n",
              "      <td>0.144752</td>\n",
              "      <td>0.174812</td>\n",
              "      <td>0.087941</td>\n",
              "      <td>0.074424</td>\n",
              "      <td>0.089609</td>\n",
              "      <td>0.003455</td>\n",
              "      <td>0.147541</td>\n",
              "      <td>0.054193</td>\n",
              "      <td>0.069555</td>\n",
              "      <td>0.084488</td>\n",
              "      <td>0.120292</td>\n",
              "      <td>0.035471</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.075619</td>\n",
              "      <td>0.019626</td>\n",
              "      <td>0.117394</td>\n",
              "      <td>0.084735</td>\n",
              "      <td>0.090601</td>\n",
              "      <td>0.078083</td>\n",
              "      <td>0.117891</td>\n",
              "      <td>0.043688</td>\n",
              "      <td>0.043688</td>\n",
              "      <td>0.084241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.050223</td>\n",
              "      <td>0.075212</td>\n",
              "      <td>0</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.050223</td>\n",
              "      <td>0.126632</td>\n",
              "      <td>0.151621</td>\n",
              "      <td>0.076409</td>\n",
              "      <td>0.126632</td>\n",
              "      <td>0.076875</td>\n",
              "      <td>0.101864</td>\n",
              "      <td>0.026652</td>\n",
              "      <td>0.076875</td>\n",
              "      <td>0.049757</td>\n",
              "      <td>0.156209</td>\n",
              "      <td>0.181198</td>\n",
              "      <td>0.105986</td>\n",
              "      <td>0.156209</td>\n",
              "      <td>0.029577</td>\n",
              "      <td>0.079334</td>\n",
              "      <td>0.114409</td>\n",
              "      <td>0.139399</td>\n",
              "      <td>0.064187</td>\n",
              "      <td>0.114409</td>\n",
              "      <td>0.012222</td>\n",
              "      <td>0.037534</td>\n",
              "      <td>0.041800</td>\n",
              "      <td>0.137521</td>\n",
              "      <td>0.162510</td>\n",
              "      <td>0.087298</td>\n",
              "      <td>0.137521</td>\n",
              "      <td>0.010889</td>\n",
              "      <td>0.060646</td>\n",
              "      <td>0.018688</td>\n",
              "      <td>0.023111</td>\n",
              "      <td>0.025548</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>0.075770</td>\n",
              "      <td>0.025548</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275644</td>\n",
              "      <td>0.318238</td>\n",
              "      <td>0.310798</td>\n",
              "      <td>0.261226</td>\n",
              "      <td>0.385062</td>\n",
              "      <td>0.385062</td>\n",
              "      <td>0.024101</td>\n",
              "      <td>0.049090</td>\n",
              "      <td>0.026121</td>\n",
              "      <td>0.024101</td>\n",
              "      <td>0.102531</td>\n",
              "      <td>0.052774</td>\n",
              "      <td>0.132108</td>\n",
              "      <td>0.090308</td>\n",
              "      <td>0.113420</td>\n",
              "      <td>0.049648</td>\n",
              "      <td>0.087579</td>\n",
              "      <td>0.126865</td>\n",
              "      <td>0.111339</td>\n",
              "      <td>0.166021</td>\n",
              "      <td>0.098746</td>\n",
              "      <td>0.102437</td>\n",
              "      <td>0.038643</td>\n",
              "      <td>0.076978</td>\n",
              "      <td>0.151718</td>\n",
              "      <td>0.021442</td>\n",
              "      <td>0.111813</td>\n",
              "      <td>0.082358</td>\n",
              "      <td>0.045167</td>\n",
              "      <td>0.046630</td>\n",
              "      <td>0.049152</td>\n",
              "      <td>0.004887</td>\n",
              "      <td>0.117996</td>\n",
              "      <td>0.085317</td>\n",
              "      <td>0.042723</td>\n",
              "      <td>0.050163</td>\n",
              "      <td>0.099735</td>\n",
              "      <td>0.024101</td>\n",
              "      <td>0.024101</td>\n",
              "      <td>0.360961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.031143</td>\n",
              "      <td>0.061256</td>\n",
              "      <td>0.030114</td>\n",
              "      <td>0</td>\n",
              "      <td>0.031143</td>\n",
              "      <td>0.061256</td>\n",
              "      <td>0.048167</td>\n",
              "      <td>0.017024</td>\n",
              "      <td>0.013089</td>\n",
              "      <td>0.048167</td>\n",
              "      <td>0.134764</td>\n",
              "      <td>0.103621</td>\n",
              "      <td>0.073507</td>\n",
              "      <td>0.134764</td>\n",
              "      <td>0.086597</td>\n",
              "      <td>0.141375</td>\n",
              "      <td>0.110232</td>\n",
              "      <td>0.080119</td>\n",
              "      <td>0.141375</td>\n",
              "      <td>0.093208</td>\n",
              "      <td>0.006611</td>\n",
              "      <td>0.126412</td>\n",
              "      <td>0.095269</td>\n",
              "      <td>0.065156</td>\n",
              "      <td>0.126412</td>\n",
              "      <td>0.078245</td>\n",
              "      <td>0.008352</td>\n",
              "      <td>0.014963</td>\n",
              "      <td>0.195353</td>\n",
              "      <td>0.164210</td>\n",
              "      <td>0.134097</td>\n",
              "      <td>0.195353</td>\n",
              "      <td>0.147186</td>\n",
              "      <td>0.060590</td>\n",
              "      <td>0.053978</td>\n",
              "      <td>0.068941</td>\n",
              "      <td>0.030095</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>0.031162</td>\n",
              "      <td>0.030095</td>\n",
              "      <td>...</td>\n",
              "      <td>0.133218</td>\n",
              "      <td>0.142490</td>\n",
              "      <td>0.107539</td>\n",
              "      <td>0.149699</td>\n",
              "      <td>0.224556</td>\n",
              "      <td>0.224556</td>\n",
              "      <td>0.024287</td>\n",
              "      <td>0.055429</td>\n",
              "      <td>0.085543</td>\n",
              "      <td>0.024287</td>\n",
              "      <td>0.072454</td>\n",
              "      <td>0.159050</td>\n",
              "      <td>0.165662</td>\n",
              "      <td>0.150699</td>\n",
              "      <td>0.219640</td>\n",
              "      <td>0.054381</td>\n",
              "      <td>0.171454</td>\n",
              "      <td>0.171289</td>\n",
              "      <td>0.169075</td>\n",
              "      <td>0.168031</td>\n",
              "      <td>0.223654</td>\n",
              "      <td>0.136651</td>\n",
              "      <td>0.120110</td>\n",
              "      <td>0.173127</td>\n",
              "      <td>0.261584</td>\n",
              "      <td>0.180769</td>\n",
              "      <td>0.076161</td>\n",
              "      <td>0.159417</td>\n",
              "      <td>0.056674</td>\n",
              "      <td>0.103605</td>\n",
              "      <td>0.145995</td>\n",
              "      <td>0.142238</td>\n",
              "      <td>0.250164</td>\n",
              "      <td>0.115625</td>\n",
              "      <td>0.106353</td>\n",
              "      <td>0.141304</td>\n",
              "      <td>0.099144</td>\n",
              "      <td>0.024287</td>\n",
              "      <td>0.024287</td>\n",
              "      <td>0.248843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 595 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         f1        f2        f3  f4  ...      f592      f593      f594      f595\n",
              "0  0.100531  0.032178  0.132709   0  ...  0.139791  0.055889  0.055889  0.218214\n",
              "1  0.014826  0.071366  0.056540   0  ...  0.056305  0.008621  0.008621  0.222214\n",
              "2  0.097006  0.099051  0.196056   0  ...  0.117891  0.043688  0.043688  0.084241\n",
              "3  0.024989  0.050223  0.075212   0  ...  0.099735  0.024101  0.024101  0.360961\n",
              "4  0.031143  0.061256  0.030114   0  ...  0.099144  0.024287  0.024287  0.248843\n",
              "\n",
              "[5 rows x 595 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWg2UjySGkws",
        "outputId": "592094aa-5f73-4f1a-b556-700772104722"
      },
      "source": [
        "print(train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 596)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jr-fhcaG7k2",
        "outputId": "e1012cc0-bce5-47f1-d8da-e27a3d0b0216"
      },
      "source": [
        "pca = PCA(whiten=True)\n",
        "pca.fit(data)\n",
        "variance = pd.DataFrame(pca.explained_variance_ratio_)\n",
        "np.cumsum(pca.explained_variance_ratio_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.224933  , 0.34055914, 0.41194   , 0.47406611, 0.5260937 ,\n",
              "       0.5634532 , 0.59881892, 0.63200694, 0.66215058, 0.6887922 ,\n",
              "       0.71019499, 0.73016214, 0.74716108, 0.7630392 , 0.77814312,\n",
              "       0.79256131, 0.80501491, 0.81709319, 0.82857371, 0.83846154,\n",
              "       0.84797267, 0.85667559, 0.86500742, 0.87282312, 0.88008841,\n",
              "       0.88682917, 0.89270303, 0.89848133, 0.90399686, 0.90902141,\n",
              "       0.9139036 , 0.91815655, 0.9222748 , 0.92612756, 0.92990596,\n",
              "       0.93321069, 0.93640118, 0.93955865, 0.94254379, 0.94529901,\n",
              "       0.94791718, 0.95033645, 0.95258321, 0.95462654, 0.95656349,\n",
              "       0.95828346, 0.95995984, 0.961577  , 0.96304941, 0.96437739,\n",
              "       0.96568436, 0.96695246, 0.96817495, 0.96932601, 0.97040638,\n",
              "       0.97143337, 0.97244976, 0.97336541, 0.97427072, 0.97510283,\n",
              "       0.97589549, 0.97667951, 0.97743632, 0.97818272, 0.97890677,\n",
              "       0.97959174, 0.98027202, 0.98093661, 0.98158054, 0.98219442,\n",
              "       0.9827933 , 0.98337521, 0.98393243, 0.98446685, 0.98498223,\n",
              "       0.98549014, 0.98598149, 0.98645642, 0.98691616, 0.98734759,\n",
              "       0.98777726, 0.98818456, 0.98858432, 0.98897507, 0.98935145,\n",
              "       0.98971668, 0.99006996, 0.99041588, 0.99075417, 0.99109009,\n",
              "       0.99141487, 0.99173249, 0.99204793, 0.9923481 , 0.99263639,\n",
              "       0.99291781, 0.9931896 , 0.99345465, 0.99371163, 0.99396104,\n",
              "       0.9942046 , 0.99444303, 0.99467481, 0.9949012 , 0.99512166,\n",
              "       0.99533556, 0.99554574, 0.99574632, 0.99593397, 0.99611741,\n",
              "       0.99629531, 0.99646458, 0.99663026, 0.99679257, 0.99695301,\n",
              "       0.99711018, 0.99725621, 0.9974019 , 0.99754168, 0.99767757,\n",
              "       0.9978066 , 0.99792869, 0.99804934, 0.99816719, 0.99828009,\n",
              "       0.99838895, 0.9984961 , 0.99859926, 0.99870032, 0.99879083,\n",
              "       0.99887969, 0.99896745, 0.99905189, 0.9991339 , 0.99921335,\n",
              "       0.99929067, 0.99936407, 0.99943621, 0.99950461, 0.99956751,\n",
              "       0.99962661, 0.99968465, 0.99973879, 0.99979225, 0.99984253,\n",
              "       0.99989008, 0.99993011, 0.99996688, 1.        , 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK8ktxa4HjOk",
        "outputId": "08f6c110-b3ca-40c3-c05f-01ba9f0fbb36"
      },
      "source": [
        "pca = PCA(n_components=16,whiten=True)\n",
        "pca = pca.fit(data)\n",
        "dataPCA = pca.transform(data)\n",
        "print(dataPCA.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 16)\n",
            "(150, 596)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5TYlW_xDgtJ"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(dataPCA)\n",
        "train = scaler.transform(dataPCA)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQw0mbzzEOph",
        "outputId": "37419593-3f68-4061-c147-57e654cafcc4"
      },
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "reg = MultiOutputRegressor(SGDRegressor())\n",
        "reg.fit(train, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=SGDRegressor(alpha=0.0001, average=False,\n",
              "                                            early_stopping=False, epsilon=0.1,\n",
              "                                            eta0=0.01, fit_intercept=True,\n",
              "                                            l1_ratio=0.15,\n",
              "                                            learning_rate='invscaling',\n",
              "                                            loss='squared_loss', max_iter=1000,\n",
              "                                            n_iter_no_change=5, penalty='l2',\n",
              "                                            power_t=0.25, random_state=None,\n",
              "                                            shuffle=True, tol=0.001,\n",
              "                                            validation_fraction=0.1, verbose=0,\n",
              "                                            warm_start=False),\n",
              "                     n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKUAZuOJEgLu",
        "outputId": "74d72ae0-2b84-433a-d896-7bf803b6d911"
      },
      "source": [
        "reg.score(train, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6992226032462652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "CHu8EnnjHr8k",
        "outputId": "7ff19663-a6e9-4f35-adca-ced49348d797"
      },
      "source": [
        "# R2 Score\n",
        "\n",
        "def lets_try(train,labels):\n",
        "    results={}\n",
        "    test = train[-15:]\n",
        "    test_labels = labels[-15:]\n",
        "    train = train[:-15]\n",
        "    train_labels = labels[:-15]\n",
        "    print(train.shape)\n",
        "    print(test.shape)\n",
        "    print(train_labels.shape)\n",
        "    print(test_labels.shape)\n",
        "    def test_model(clf):\n",
        "        \n",
        "        # cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
        "        # r2 = make_scorer(mean_squared_error)\n",
        "        # r2_val_score = cross_val_score(clf, train, labels, cv=cv,scoring=r2)\n",
        "        # scores=[r2_val_score.mean()]\n",
        "        \n",
        "        clf.fit(train, train_labels)\n",
        "        test_predict = clf.predict(test)\n",
        "        scores = mean_squared_error(test_labels, test_predict)\n",
        "\n",
        "        return [scores]\n",
        "\n",
        "    clf = linear_model.LinearRegression()\n",
        "    print(f\"Linear Regression = {test_model(clf)}\")\n",
        "    \n",
        "    clf = linear_model.Ridge()\n",
        "    print(f\"Ridge = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(SGDRegressor())\n",
        "    print(f\"SGDRegressor = {test_model(clf)}\")\n",
        "\n",
        "    clf = MultiOutputRegressor(linear_model.BayesianRidge())\n",
        "    print(f\"BayesianRidge = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(linear_model.HuberRegressor())\n",
        "    print(f\"HuberRegressor= {test_model(clf)}\")\n",
        "    \n",
        "    clf = linear_model.Lasso(alpha=1e-4)\n",
        "    print(f\"Lasso = {test_model(clf)}\")\n",
        "        \n",
        "    clf = BaggingRegressor()\n",
        "    print(f\"BaggingRegressor = {test_model(clf)}\")\n",
        "\n",
        "    clf = ElasticNet()\n",
        "    print(f\"ElasticNet = {test_model(clf)}\")\n",
        "    \n",
        "    clf = RandomForestRegressor()\n",
        "    print(f\"RandomForestRegressor= {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(AdaBoostRegressor())\n",
        "    print(f\"AdaBoostRegressor = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(svm.SVR())\n",
        "    print(f\"SVM RBF = {test_model(clf)}\")\n",
        "    \n",
        "    clf = MultiOutputRegressor(svm.SVR(kernel=\"linear\"))\n",
        "    print(f\"SVM Linear = {test_model(clf)}\")\n",
        "       \n",
        "    clf = MultiOutputRegressor(svm.SVR(kernel=\"rbf\"))\n",
        "    print(f\"SVM Linear rbf {test_model(clf)}\")\n",
        "    \n",
        "    # results = pd.DataFrame.from_dict(results,orient='index')\n",
        "    # results.columns=[\"MSE\"] \n",
        "    # results=results.sort(columns=[\"MSE\"],ascending=False)\n",
        "    # results.plot(kind=\"bar\",title=\"Model Scores\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.5,1])\n",
        "    # return results\n",
        "\n",
        "# lets_try(train,train_labels)\n",
        "# print(train_labels.shape)\n",
        "lets_try(, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135, 16)\n",
            "(15, 16)\n",
            "(135, 596)\n",
            "(15, 596)\n",
            "Linear Regression = [8.70361583403411]\n",
            "Ridge = [8.704807448317013]\n",
            "SGDRegressor = [8.711770974619624]\n",
            "BayesianRidge = [9.471460483134171]\n",
            "HuberRegressor= [8.70897055428651]\n",
            "Lasso = [8.703610077548264]\n",
            "BaggingRegressor = [8.572025807131237]\n",
            "BaggingRegressor = [8.930873038434518]\n",
            "ElasticNet = [8.930426473499065]\n",
            "RandomForestRegressor= [9.275201109403072]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8f807a3c4c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# lets_try(train,train_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# print(train_labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mlets_try\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataPCA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-8f807a3c4c1f>\u001b[0m in \u001b[0;36mlets_try\u001b[0;34m(train, labels)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"AdaBoostRegressor = {test_model(clf)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-8f807a3c4c1f>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# scores=[r2_val_score.mean()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    168\u001b[0m             delayed(_fit_estimator)(\n\u001b[1;32m    169\u001b[0m                 self.estimator, X, y[:, i], sample_weight)\n\u001b[0;32m--> 170\u001b[0;31m             for i in range(y.shape[1]))\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0merror_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;31m# DataFrame), and store them. If not, store None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0mdtypes_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mdtypes_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# pandas boolean dtype __array__ interface coerces bools to objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvHrH3dRMeER",
        "outputId": "17e44586-ad4f-4380-c036-bb218c659b53"
      },
      "source": [
        "import xgboost\n",
        "clf = BaggingRegressor()\n",
        "clf.fit(data, label)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
              "                 max_features=1.0, max_samples=1.0, n_estimators=10,\n",
              "                 n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
              "                 warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "HBAKsf1MSSW-",
        "outputId": "afc3c397-1649-4e3f-947e-369c4c202a6a"
      },
      "source": [
        "test = pd.read_csv('test_t0.csv')\n",
        "test = test.drop(\"ID\",1)\n",
        "print(test.shape)\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 595)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>...</th>\n",
              "      <th>f556</th>\n",
              "      <th>f557</th>\n",
              "      <th>f558</th>\n",
              "      <th>f559</th>\n",
              "      <th>f560</th>\n",
              "      <th>f561</th>\n",
              "      <th>f562</th>\n",
              "      <th>f563</th>\n",
              "      <th>f564</th>\n",
              "      <th>f565</th>\n",
              "      <th>f566</th>\n",
              "      <th>f567</th>\n",
              "      <th>f568</th>\n",
              "      <th>f569</th>\n",
              "      <th>f570</th>\n",
              "      <th>f571</th>\n",
              "      <th>f572</th>\n",
              "      <th>f573</th>\n",
              "      <th>f574</th>\n",
              "      <th>f575</th>\n",
              "      <th>f576</th>\n",
              "      <th>f577</th>\n",
              "      <th>f578</th>\n",
              "      <th>f579</th>\n",
              "      <th>f580</th>\n",
              "      <th>f581</th>\n",
              "      <th>f582</th>\n",
              "      <th>f583</th>\n",
              "      <th>f584</th>\n",
              "      <th>f585</th>\n",
              "      <th>f586</th>\n",
              "      <th>f587</th>\n",
              "      <th>f588</th>\n",
              "      <th>f589</th>\n",
              "      <th>f590</th>\n",
              "      <th>f591</th>\n",
              "      <th>f592</th>\n",
              "      <th>f593</th>\n",
              "      <th>f594</th>\n",
              "      <th>f595</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.122661</td>\n",
              "      <td>0.109112</td>\n",
              "      <td>0.231773</td>\n",
              "      <td>0</td>\n",
              "      <td>0.122661</td>\n",
              "      <td>0.109112</td>\n",
              "      <td>0.092518</td>\n",
              "      <td>0.215179</td>\n",
              "      <td>0.016593</td>\n",
              "      <td>0.092518</td>\n",
              "      <td>0.145721</td>\n",
              "      <td>0.268382</td>\n",
              "      <td>0.036609</td>\n",
              "      <td>0.145721</td>\n",
              "      <td>0.053202</td>\n",
              "      <td>0.207891</td>\n",
              "      <td>0.330552</td>\n",
              "      <td>0.098779</td>\n",
              "      <td>0.207891</td>\n",
              "      <td>0.115373</td>\n",
              "      <td>0.062170</td>\n",
              "      <td>0.105800</td>\n",
              "      <td>0.228461</td>\n",
              "      <td>0.003311</td>\n",
              "      <td>0.105800</td>\n",
              "      <td>0.013282</td>\n",
              "      <td>0.039920</td>\n",
              "      <td>0.102091</td>\n",
              "      <td>0.136860</td>\n",
              "      <td>0.259521</td>\n",
              "      <td>0.027748</td>\n",
              "      <td>0.136860</td>\n",
              "      <td>0.044342</td>\n",
              "      <td>0.008861</td>\n",
              "      <td>0.071031</td>\n",
              "      <td>0.031060</td>\n",
              "      <td>0.018215</td>\n",
              "      <td>0.140876</td>\n",
              "      <td>0.090897</td>\n",
              "      <td>0.018215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047609</td>\n",
              "      <td>0.112625</td>\n",
              "      <td>0.125787</td>\n",
              "      <td>0.124356</td>\n",
              "      <td>0.215772</td>\n",
              "      <td>0.215772</td>\n",
              "      <td>0.004597</td>\n",
              "      <td>0.127258</td>\n",
              "      <td>0.104515</td>\n",
              "      <td>0.004597</td>\n",
              "      <td>0.087922</td>\n",
              "      <td>0.141124</td>\n",
              "      <td>0.203295</td>\n",
              "      <td>0.101204</td>\n",
              "      <td>0.132264</td>\n",
              "      <td>0.013619</td>\n",
              "      <td>0.176267</td>\n",
              "      <td>0.120791</td>\n",
              "      <td>0.196560</td>\n",
              "      <td>0.163665</td>\n",
              "      <td>0.207902</td>\n",
              "      <td>0.065500</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.026432</td>\n",
              "      <td>0.187328</td>\n",
              "      <td>0.026848</td>\n",
              "      <td>0.093334</td>\n",
              "      <td>0.115236</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.052192</td>\n",
              "      <td>0.083222</td>\n",
              "      <td>0.155292</td>\n",
              "      <td>0.176474</td>\n",
              "      <td>0.163567</td>\n",
              "      <td>0.098551</td>\n",
              "      <td>0.085389</td>\n",
              "      <td>0.086820</td>\n",
              "      <td>0.004597</td>\n",
              "      <td>0.004597</td>\n",
              "      <td>0.211176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.045889</td>\n",
              "      <td>0.077398</td>\n",
              "      <td>0.031509</td>\n",
              "      <td>0</td>\n",
              "      <td>0.045889</td>\n",
              "      <td>0.077398</td>\n",
              "      <td>0.181591</td>\n",
              "      <td>0.135702</td>\n",
              "      <td>0.104193</td>\n",
              "      <td>0.181591</td>\n",
              "      <td>0.079100</td>\n",
              "      <td>0.033211</td>\n",
              "      <td>0.001702</td>\n",
              "      <td>0.079100</td>\n",
              "      <td>0.102491</td>\n",
              "      <td>0.109561</td>\n",
              "      <td>0.063672</td>\n",
              "      <td>0.032163</td>\n",
              "      <td>0.109561</td>\n",
              "      <td>0.072030</td>\n",
              "      <td>0.030461</td>\n",
              "      <td>0.104044</td>\n",
              "      <td>0.058154</td>\n",
              "      <td>0.026646</td>\n",
              "      <td>0.104044</td>\n",
              "      <td>0.077547</td>\n",
              "      <td>0.024944</td>\n",
              "      <td>0.005517</td>\n",
              "      <td>0.181465</td>\n",
              "      <td>0.135576</td>\n",
              "      <td>0.104067</td>\n",
              "      <td>0.181465</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.102365</td>\n",
              "      <td>0.071904</td>\n",
              "      <td>0.077421</td>\n",
              "      <td>0.002626</td>\n",
              "      <td>0.043263</td>\n",
              "      <td>0.074772</td>\n",
              "      <td>0.002626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056347</td>\n",
              "      <td>0.081727</td>\n",
              "      <td>0.075073</td>\n",
              "      <td>0.080828</td>\n",
              "      <td>0.177357</td>\n",
              "      <td>0.177357</td>\n",
              "      <td>0.002731</td>\n",
              "      <td>0.048621</td>\n",
              "      <td>0.080129</td>\n",
              "      <td>0.002731</td>\n",
              "      <td>0.184322</td>\n",
              "      <td>0.081831</td>\n",
              "      <td>0.112292</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.184197</td>\n",
              "      <td>0.005358</td>\n",
              "      <td>0.152657</td>\n",
              "      <td>0.110212</td>\n",
              "      <td>0.131043</td>\n",
              "      <td>0.210307</td>\n",
              "      <td>0.115340</td>\n",
              "      <td>0.139567</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.131111</td>\n",
              "      <td>0.134455</td>\n",
              "      <td>0.058544</td>\n",
              "      <td>0.080568</td>\n",
              "      <td>0.159891</td>\n",
              "      <td>0.025726</td>\n",
              "      <td>0.076265</td>\n",
              "      <td>0.087444</td>\n",
              "      <td>0.107125</td>\n",
              "      <td>0.168047</td>\n",
              "      <td>0.123742</td>\n",
              "      <td>0.098362</td>\n",
              "      <td>0.105015</td>\n",
              "      <td>0.099260</td>\n",
              "      <td>0.002731</td>\n",
              "      <td>0.002731</td>\n",
              "      <td>0.180088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.020038</td>\n",
              "      <td>0.026596</td>\n",
              "      <td>0.046635</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020038</td>\n",
              "      <td>0.026596</td>\n",
              "      <td>0.114418</td>\n",
              "      <td>0.134456</td>\n",
              "      <td>0.087822</td>\n",
              "      <td>0.114418</td>\n",
              "      <td>0.180229</td>\n",
              "      <td>0.200267</td>\n",
              "      <td>0.153633</td>\n",
              "      <td>0.180229</td>\n",
              "      <td>0.065811</td>\n",
              "      <td>0.177262</td>\n",
              "      <td>0.197300</td>\n",
              "      <td>0.150666</td>\n",
              "      <td>0.177262</td>\n",
              "      <td>0.062844</td>\n",
              "      <td>0.002967</td>\n",
              "      <td>0.136511</td>\n",
              "      <td>0.156549</td>\n",
              "      <td>0.109914</td>\n",
              "      <td>0.136511</td>\n",
              "      <td>0.022092</td>\n",
              "      <td>0.043718</td>\n",
              "      <td>0.040751</td>\n",
              "      <td>0.244241</td>\n",
              "      <td>0.264279</td>\n",
              "      <td>0.217645</td>\n",
              "      <td>0.244241</td>\n",
              "      <td>0.129823</td>\n",
              "      <td>0.064012</td>\n",
              "      <td>0.066979</td>\n",
              "      <td>0.107731</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.012537</td>\n",
              "      <td>0.034097</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139746</td>\n",
              "      <td>0.083844</td>\n",
              "      <td>0.133137</td>\n",
              "      <td>0.168949</td>\n",
              "      <td>0.236086</td>\n",
              "      <td>0.236086</td>\n",
              "      <td>0.090372</td>\n",
              "      <td>0.070334</td>\n",
              "      <td>0.116968</td>\n",
              "      <td>0.090372</td>\n",
              "      <td>0.204790</td>\n",
              "      <td>0.270601</td>\n",
              "      <td>0.267634</td>\n",
              "      <td>0.226883</td>\n",
              "      <td>0.334613</td>\n",
              "      <td>0.082871</td>\n",
              "      <td>0.265359</td>\n",
              "      <td>0.247751</td>\n",
              "      <td>0.239643</td>\n",
              "      <td>0.292382</td>\n",
              "      <td>0.241814</td>\n",
              "      <td>0.268363</td>\n",
              "      <td>0.193135</td>\n",
              "      <td>0.160032</td>\n",
              "      <td>0.205748</td>\n",
              "      <td>0.116001</td>\n",
              "      <td>0.050774</td>\n",
              "      <td>0.219221</td>\n",
              "      <td>0.058565</td>\n",
              "      <td>0.132854</td>\n",
              "      <td>0.189319</td>\n",
              "      <td>0.125778</td>\n",
              "      <td>0.253501</td>\n",
              "      <td>0.186712</td>\n",
              "      <td>0.242613</td>\n",
              "      <td>0.193321</td>\n",
              "      <td>0.157509</td>\n",
              "      <td>0.090372</td>\n",
              "      <td>0.090372</td>\n",
              "      <td>0.326458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.015838</td>\n",
              "      <td>0.073108</td>\n",
              "      <td>0.057270</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015838</td>\n",
              "      <td>0.073108</td>\n",
              "      <td>0.112882</td>\n",
              "      <td>0.097044</td>\n",
              "      <td>0.039774</td>\n",
              "      <td>0.112882</td>\n",
              "      <td>0.281027</td>\n",
              "      <td>0.265189</td>\n",
              "      <td>0.207919</td>\n",
              "      <td>0.281027</td>\n",
              "      <td>0.168146</td>\n",
              "      <td>0.077977</td>\n",
              "      <td>0.062139</td>\n",
              "      <td>0.004869</td>\n",
              "      <td>0.077977</td>\n",
              "      <td>0.034905</td>\n",
              "      <td>0.203050</td>\n",
              "      <td>0.123877</td>\n",
              "      <td>0.108039</td>\n",
              "      <td>0.050769</td>\n",
              "      <td>0.123877</td>\n",
              "      <td>0.010995</td>\n",
              "      <td>0.157150</td>\n",
              "      <td>0.045900</td>\n",
              "      <td>0.151164</td>\n",
              "      <td>0.135326</td>\n",
              "      <td>0.078056</td>\n",
              "      <td>0.151164</td>\n",
              "      <td>0.038282</td>\n",
              "      <td>0.129863</td>\n",
              "      <td>0.073187</td>\n",
              "      <td>0.027287</td>\n",
              "      <td>0.014713</td>\n",
              "      <td>0.001125</td>\n",
              "      <td>0.058395</td>\n",
              "      <td>0.014713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135869</td>\n",
              "      <td>0.142534</td>\n",
              "      <td>0.112490</td>\n",
              "      <td>0.172141</td>\n",
              "      <td>0.237667</td>\n",
              "      <td>0.237667</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.012912</td>\n",
              "      <td>0.070182</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.109955</td>\n",
              "      <td>0.278101</td>\n",
              "      <td>0.075051</td>\n",
              "      <td>0.120951</td>\n",
              "      <td>0.148238</td>\n",
              "      <td>0.011787</td>\n",
              "      <td>0.148583</td>\n",
              "      <td>0.113695</td>\n",
              "      <td>0.114933</td>\n",
              "      <td>0.205219</td>\n",
              "      <td>0.170457</td>\n",
              "      <td>0.113402</td>\n",
              "      <td>0.075274</td>\n",
              "      <td>0.058549</td>\n",
              "      <td>0.129987</td>\n",
              "      <td>0.145470</td>\n",
              "      <td>0.050776</td>\n",
              "      <td>0.101857</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.069858</td>\n",
              "      <td>0.072407</td>\n",
              "      <td>0.051349</td>\n",
              "      <td>0.140081</td>\n",
              "      <td>0.098872</td>\n",
              "      <td>0.092207</td>\n",
              "      <td>0.122251</td>\n",
              "      <td>0.062600</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.234741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.007235</td>\n",
              "      <td>0.048022</td>\n",
              "      <td>0.040787</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007235</td>\n",
              "      <td>0.048022</td>\n",
              "      <td>0.135871</td>\n",
              "      <td>0.128635</td>\n",
              "      <td>0.087848</td>\n",
              "      <td>0.135871</td>\n",
              "      <td>0.314094</td>\n",
              "      <td>0.306859</td>\n",
              "      <td>0.266072</td>\n",
              "      <td>0.314094</td>\n",
              "      <td>0.178223</td>\n",
              "      <td>0.118140</td>\n",
              "      <td>0.110905</td>\n",
              "      <td>0.070118</td>\n",
              "      <td>0.118140</td>\n",
              "      <td>0.017730</td>\n",
              "      <td>0.195954</td>\n",
              "      <td>0.093777</td>\n",
              "      <td>0.086542</td>\n",
              "      <td>0.045755</td>\n",
              "      <td>0.093777</td>\n",
              "      <td>0.042093</td>\n",
              "      <td>0.220317</td>\n",
              "      <td>0.024363</td>\n",
              "      <td>0.204410</td>\n",
              "      <td>0.197175</td>\n",
              "      <td>0.156388</td>\n",
              "      <td>0.204410</td>\n",
              "      <td>0.068540</td>\n",
              "      <td>0.109684</td>\n",
              "      <td>0.086270</td>\n",
              "      <td>0.110633</td>\n",
              "      <td>0.017383</td>\n",
              "      <td>0.024618</td>\n",
              "      <td>0.065405</td>\n",
              "      <td>0.017383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073855</td>\n",
              "      <td>0.081441</td>\n",
              "      <td>0.093111</td>\n",
              "      <td>0.152142</td>\n",
              "      <td>0.215760</td>\n",
              "      <td>0.215760</td>\n",
              "      <td>0.002288</td>\n",
              "      <td>0.004948</td>\n",
              "      <td>0.045735</td>\n",
              "      <td>0.002288</td>\n",
              "      <td>0.133583</td>\n",
              "      <td>0.311806</td>\n",
              "      <td>0.115853</td>\n",
              "      <td>0.091490</td>\n",
              "      <td>0.202123</td>\n",
              "      <td>0.019670</td>\n",
              "      <td>0.119562</td>\n",
              "      <td>0.102787</td>\n",
              "      <td>0.090560</td>\n",
              "      <td>0.267360</td>\n",
              "      <td>0.176748</td>\n",
              "      <td>0.144538</td>\n",
              "      <td>0.066852</td>\n",
              "      <td>0.085370</td>\n",
              "      <td>0.093304</td>\n",
              "      <td>0.139875</td>\n",
              "      <td>0.129553</td>\n",
              "      <td>0.138968</td>\n",
              "      <td>0.051438</td>\n",
              "      <td>0.047755</td>\n",
              "      <td>0.057658</td>\n",
              "      <td>0.070526</td>\n",
              "      <td>0.123818</td>\n",
              "      <td>0.139617</td>\n",
              "      <td>0.132032</td>\n",
              "      <td>0.120361</td>\n",
              "      <td>0.061331</td>\n",
              "      <td>0.002288</td>\n",
              "      <td>0.002288</td>\n",
              "      <td>0.213473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 595 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         f1        f2        f3  f4  ...      f592      f593      f594      f595\n",
              "0  0.122661  0.109112  0.231773   0  ...  0.086820  0.004597  0.004597  0.211176\n",
              "1  0.045889  0.077398  0.031509   0  ...  0.099260  0.002731  0.002731  0.180088\n",
              "2  0.020038  0.026596  0.046635   0  ...  0.157509  0.090372  0.090372  0.326458\n",
              "3  0.015838  0.073108  0.057270   0  ...  0.062600  0.002926  0.002926  0.234741\n",
              "4  0.007235  0.048022  0.040787   0  ...  0.061331  0.002288  0.002288  0.213473\n",
              "\n",
              "[5 rows x 595 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "twjp8maZSHBS",
        "outputId": "2f722d6e-892e-4301-aedc-cec4aa221f81"
      },
      "source": [
        "test = pca.transform(test)\n",
        "prediction = clf.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6372069c49fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (80,130) (595,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGz0pJvgSvOE"
      },
      "source": [
        "print(prediction.shape)\n",
        "df = pd.DataFrame(prediction)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0nhdwTkUKX_"
      },
      "source": [
        ";batu_flat = df.values.flatten()\n",
        "print(batu_flat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGrb82elS6fK",
        "outputId": "075fea2f-e75b-4649-9d5a-c785e322e49c"
      },
      "source": [
        "meltedDF = df.to_numpy().flatten()\n",
        "print(meltedDF.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "26B9HMAAT1qo",
        "outputId": "5587fc68-4705-4c3d-9013-d3e528a1c73f"
      },
      "source": [
        "anan = pd.DataFrame(meltedDF)\n",
        "anan.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.061191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.069773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.100056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0  0.061191\n",
              "1  0.069773\n",
              "2  0.100056\n",
              "3  0.000000\n",
              "4  0.061191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx8oDlz2US41"
      },
      "source": [
        "# anan.insert(0, \"ID\", np.arange(1, anan.shape[0]+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Uoe2LhOlVkI5",
        "outputId": "19a7e671-7647-40eb-db37-6ac5b5f93592"
      },
      "source": [
        "anan.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.061191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.069773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.100056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0  0.061191\n",
              "1  0.069773\n",
              "2  0.100056\n",
              "3  0.000000\n",
              "4  0.061191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "O55D-Bd6U_bt",
        "outputId": "ce42d808-c56a-4bec-8cfd-1169165a0a42"
      },
      "source": [
        "anan.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47595</th>\n",
              "      <td>0.134184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47596</th>\n",
              "      <td>0.134456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47597</th>\n",
              "      <td>0.037313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47598</th>\n",
              "      <td>0.037313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47599</th>\n",
              "      <td>0.310460</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0\n",
              "47595  0.134184\n",
              "47596  0.134456\n",
              "47597  0.037313\n",
              "47598  0.037313\n",
              "47599  0.310460"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1uA0y_bVWNE",
        "outputId": "5a223c06-d2df-42d5-f221-cec93a449a35"
      },
      "source": [
        "print(anan.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQbCmkdrVqLO"
      },
      "source": [
        "baban = anan.rename(columns={0: \"predicted\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-dsJa2zqVzQg",
        "outputId": "d24422f7-3d5f-4e49-cb18-d1a99480c070"
      },
      "source": [
        "baban.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.061191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.069773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.100056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   predicted\n",
              "0   0.061191\n",
              "1   0.069773\n",
              "2   0.100056\n",
              "3   0.000000\n",
              "4   0.061191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fmM4ZmV0Ai"
      },
      "source": [
        "csvdosyasiseysi = baban.to_csv(\"test_results2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "b_vCM_j7IsBW",
        "outputId": "1439dd33-f85f-40cd-e3f9-badbd3f85eb7"
      },
      "source": [
        " from xgboost import XGBRFRegressor\n",
        " model = MultiOutputRegressor(XGBRFRegressor(objective='reg:squarederror', n_estimators=100, verbosity=0, subsmaple=0.9, colsample_bynode=0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e03fd5543702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRFRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiOutputRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBRFRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reg:squarederror'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsmaple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bynode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'MultiOutputRegressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY7PGCo0Kbf2",
        "outputId": "9406b743-12ac-4df1-b6eb-3385dafa29e7"
      },
      "source": [
        "model.fit(dataPCA, label)\n",
        "prediction = model.predict(dataPCA)\n",
        "scores = mean_squared_error(prediction, label)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.002625866532645193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15FI6idiLBIO",
        "outputId": "6d453336-7e20-450e-9725-70eb130e6023"
      },
      "source": [
        "test = pd.read_csv('test_t0.csv')\n",
        "test = test.drop(\"ID\",1)\n",
        "print(test.shape)\n",
        "prediction = model.predict(pca.transform(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 595)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdDsNYLmMusj",
        "outputId": "9cfaf781-fb68-4c2b-b352-2d06788d3054"
      },
      "source": [
        "print(prediction.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 595)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dawi41eLSnT",
        "outputId": "62ab27c5-66a2-4444-8809-7ae4a4a409b3"
      },
      "source": [
        "prediction2 = pd.DataFrame(prediction.flatten())\n",
        "prediction2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47600, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuzolpJNLZ6H"
      },
      "source": [
        "pre3 = prediction2.rename(columns={0:\"predicted\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4QHhhUHL8DV",
        "outputId": "aa01c5a3-8c63-4104-ee6f-c5e73758b2e0"
      },
      "source": [
        "pre3.index.name = \"ID\"\n",
        "print(pre3.shape)\n",
        "pre3.to_csv(\"deneme.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(47600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2o6y_2TWdA-"
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0T_JE61I3sI"
      },
      "source": [
        "n_scores = cross_val_score(model, dataPCA, label, scoring='neg_mean_squared_error', cv=cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzuVRXj9JLOh"
      },
      "source": [
        "model.fit(dataPCA, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5fBfTj4JOl8"
      },
      "source": [
        "print(n_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPqaeYsWJxob",
        "outputId": "94669baf-abdf-4843-da94-358088aa8c9b"
      },
      "source": [
        "prediction.shape == (80, 595)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "qXQyTTaCOqwd",
        "outputId": "5543f110-df14-41cd-8b13-96832ca30a96"
      },
      "source": [
        "make_submission(prediction, \"deneme2.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deneme2.csv saved at /content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.048186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.084227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.076308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.048186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47595</th>\n",
              "      <td>0.129521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47596</th>\n",
              "      <td>0.124411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47597</th>\n",
              "      <td>0.039825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47598</th>\n",
              "      <td>0.039825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47599</th>\n",
              "      <td>0.272352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47600 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted\n",
              "ID              \n",
              "0       0.048186\n",
              "1       0.084227\n",
              "2       0.076308\n",
              "3       0.004137\n",
              "4       0.048186\n",
              "...          ...\n",
              "47595   0.129521\n",
              "47596   0.124411\n",
              "47597   0.039825\n",
              "47598   0.039825\n",
              "47599   0.272352\n",
              "\n",
              "[47600 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5y-2xLAOuk-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAuEZ3fudoAn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR0KcyvEdaVN"
      },
      "source": [
        "### KFold = n_split=10 results\n",
        "(135, 19)\n",
        "(15, 19)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.005802272956797038]\n",
        "Ridge = [0.005799988728181303]\n",
        "BayesianRidge = [0.004297786222005502]\n",
        "HuberRegressor= [0.004622051656589287]\n",
        "Lasso = [0.005790250820408533]\n",
        "BaggingRegressor = [0.004056072586337191]\n",
        "ElasticNet = [0.0030826790406581098]\n",
        "RandomForestRegressor= [0.00402007929036715]\n",
        "AdaBoostRegressor = [0.0041291666017797945]\n",
        "SVM RBF = [0.0054829324623424285]\n",
        "SVM Linear = [0.007069600173376448]\n",
        "SVM Linear rbf [0.0054829324623424285]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.006744191885778283]\n",
        "Ridge = [0.006743680477484871]\n",
        "BayesianRidge = [0.006507214061402251]\n",
        "HuberRegressor= [0.006800372756951189]\n",
        "Lasso = [0.006742680791274501]\n",
        "BaggingRegressor = [0.008102009029265259]\n",
        "ElasticNet = [0.0069362924667603545]\n",
        "RandomForestRegressor= [0.010728668527239145]\n",
        "AdaBoostRegressor = [0.009640671034316697]\n",
        "SVM RBF = [0.007188838358384941]\n",
        "SVM Linear = [0.007198396567356369]\n",
        "SVM Linear rbf [0.007188838358384941]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.0023045183308133764]\n",
        "Ridge = [0.0023041497995984583]\n",
        "BayesianRidge = [0.0021378877788895876]\n",
        "HuberRegressor= [0.0021207545646454214]\n",
        "Lasso = [0.002302697452722897]\n",
        "BaggingRegressor = [0.002598639753050235]\n",
        "ElasticNet = [0.0025102862420139298]\n",
        "RandomForestRegressor= [0.002242842157217008]\n",
        "AdaBoostRegressor = [0.0023012304887634768]\n",
        "SVM RBF = [0.004641813739452005]\n",
        "SVM Linear = [0.00367907916418258]\n",
        "SVM Linear rbf [0.004641813739452005]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.0025639376342007263]\n",
        "Ridge = [0.002563666511163113]\n",
        "BayesianRidge = [0.0024434805608064642]\n",
        "HuberRegressor= [0.002468197582583029]\n",
        "Lasso = [0.0025624369470381076]\n",
        "BaggingRegressor = [0.002487186469989797]\n",
        "ElasticNet = [0.002904297259787476]\n",
        "RandomForestRegressor= [0.002333295561098554]\n",
        "AdaBoostRegressor = [0.0025187103614842717]\n",
        "SVM RBF = [0.004504221270852039]\n",
        "SVM Linear = [0.0038039811351258303]\n",
        "SVM Linear rbf [0.004504221270852039]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.005164427021598518]\n",
        "Ridge = [0.005164167810874289]\n",
        "BayesianRidge = [0.005153677465195344]\n",
        "HuberRegressor= [0.005226145178489968]\n",
        "Lasso = [0.005164081922971847]\n",
        "BaggingRegressor = [0.005703330385007766]\n",
        "ElasticNet = [0.005776121174494068]\n",
        "RandomForestRegressor= [0.005401241834928647]\n",
        "AdaBoostRegressor = [0.005330574257363599]\n",
        "SVM RBF = [0.006677056534854889]\n",
        "SVM Linear = [0.0062700324730901634]\n",
        "SVM Linear rbf [0.006677056534854889]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.0020036552371676883]\n",
        "Ridge = [0.0020033225996146883]\n",
        "BayesianRidge = [0.0018156061980202094]\n",
        "HuberRegressor= [0.0017102318993381855]\n",
        "Lasso = [0.0020020438619769215]\n",
        "BaggingRegressor = [0.0018897397444012892]\n",
        "ElasticNet = [0.002194761461803483]\n",
        "RandomForestRegressor= [0.0017733194673465297]\n",
        "AdaBoostRegressor = [0.0019269472979016888]\n",
        "SVM RBF = [0.0038769952379162417]\n",
        "SVM Linear = [0.0033247080027624287]\n",
        "SVM Linear rbf [0.0038769952379162417]\n",
        "(135, 15)\n",
        "(15, 15)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.002786927428653145]\n",
        "Ridge = [0.002786718118785138]\n",
        "BayesianRidge = [0.0026657877284159037]\n",
        "HuberRegressor= [0.00269085722337065]\n",
        "Lasso = [0.0027858243055081905]\n",
        "BaggingRegressor = [0.002955599320451397]\n",
        "ElasticNet = [0.0028839527435591213]\n",
        "RandomForestRegressor= [0.002702839123732035]\n",
        "AdaBoostRegressor = [0.002768456849174212]\n",
        "SVM RBF = [0.004920677326775243]\n",
        "SVM Linear = [0.0038845834542473538]\n",
        "SVM Linear rbf [0.004920677326775243]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.0052766083802658495]\n",
        "Ridge = [0.005275847989638481]\n",
        "BayesianRidge = [0.004820034635472762]\n",
        "HuberRegressor= [0.005026180298915299]\n",
        "Lasso = [0.005273642590599138]\n",
        "BaggingRegressor = [0.004758714351386203]\n",
        "ElasticNet = [0.004821847827563947]\n",
        "RandomForestRegressor= [0.0045268301422334905]\n",
        "AdaBoostRegressor = [0.0046410166751561805]\n",
        "SVM RBF = [0.005492814286647762]\n",
        "SVM Linear = [0.00594884576679866]\n",
        "SVM Linear rbf [0.005492814286647762]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.010119589993062863]\n",
        "Ridge = [0.010119753227389148]\n",
        "BayesianRidge = [0.010289064935715768]\n",
        "HuberRegressor= [0.010196346157144919]\n",
        "Lasso = [0.010120091934235345]\n",
        "BaggingRegressor = [0.010162610548886604]\n",
        "ElasticNet = [0.011354407955110935]\n",
        "RandomForestRegressor= [0.009976735097034919]\n",
        "AdaBoostRegressor = [0.010271722899001794]\n",
        "SVM RBF = [0.011318486537443332]\n",
        "SVM Linear = [0.011190860576632366]\n",
        "SVM Linear rbf [0.011318486537443332]\n",
        "(135, 16)\n",
        "(15, 16)\n",
        "(135, 595)\n",
        "(15, 595)\n",
        "Linear Regression = [0.002596325787652625]\n",
        "Ridge = [0.0025961320992643933]\n",
        "BayesianRidge = [0.0025376615663518782]\n",
        "HuberRegressor= [0.002633996183132533]\n",
        "Lasso = [0.0025950992079001494]\n",
        "BaggingRegressor = [0.002507620790240666]\n",
        "ElasticNet = [0.0029951336319722984]\n",
        "RandomForestRegressor= [0.002490842896038554]\n",
        "AdaBoostRegressor = [0.0026133376407376676]\n",
        "SVM RBF = [0.004267637341080629]\n",
        "SVM Linear = [0.004026512971278571]\n",
        "SVM Linear rbf [0.004267637341080629]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD2exFXCHDey"
      },
      "source": [
        "anan = {\n",
        "    'a':[1,2],\n",
        "    'b':[3,4]\n",
        "}\n",
        "baban = {\n",
        "    'a':[3],\n",
        "    'b':[5]\n",
        "}"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZ9usr-Ugcz"
      },
      "source": [
        "anan['c'] = [5]"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZI0d18JM919",
        "outputId": "5fe879e7-710e-419e-97ac-70b0b835a4f4"
      },
      "source": [
        "anandf = pd.DataFrame(anan).T\n",
        "print(anandf)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0  1\n",
            "a  1  2\n",
            "b  3  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G_o9iFfL23n",
        "outputId": "98655f1b-9666-4a42-f279-a9f053fb234d"
      },
      "source": [
        "anandf.insert(2, \"Var\", anandf.var(axis=1))\n",
        "anandf.insert(2, \"Mean\", anandf.mean(axis=1))\n",
        "print(anandf)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0  1      Mean  Var\n",
            "a  1  2  1.166667  0.5\n",
            "b  3  4  2.500000  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "md6vmGtDL6D1",
        "outputId": "f0d9ac40-6ec7-47b5-ae74-b913e5829b61"
      },
      "source": [
        "anandf.append(3)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-635bf685ccdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manandf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7749\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7750\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7751\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7752\u001b[0m         )\n\u001b[1;32m   7753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 )\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'int'>'; only Series and DataFrame objs are valid"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcPdox0sMQB1",
        "outputId": "b5824b59-aab4-4377-c5f2-182ca34eb39d"
      },
      "source": [
        "anan = {'a':[]}\n",
        "def update(dictionariy):\n",
        "    dictionariy['a'].append(3)\n",
        "update(anan)\n",
        "print(anan)\n",
        "update(anan)\n",
        "print(anan)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': [3]}\n",
            "{'a': [3, 3]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn37weIAOHEW"
      },
      "source": [
        "clf = MultiOutputRegressor(AdaBoostRegressor())"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y78UdAJxOHan",
        "outputId": "5627b09a-1755-4cea-fd0c-8cce38ce60aa"
      },
      "source": [
        "type(clf.estimator).__name__"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AdaBoostRegressor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts3_vbcEOImA",
        "outputId": "9dcf72f2-9a94-4acb-aefd-38d758c05e37"
      },
      "source": [
        "'a' in anan.keys()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MbtFHXCOu68"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}